{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26ae2f74",
   "metadata": {},
   "source": [
    "# Recursive Framework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c556638",
   "metadata": {},
   "source": [
    "### Imports and Loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bc44e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, ShuffleSplit\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, RepeatVector, TimeDistributed, Dropout, BatchNormalization\n",
    "from tensorflow.keras.layers import Bidirectional, Conv1D, MaxPooling1D, Flatten\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import time\n",
    "import warnings\n",
    "import pickle\n",
    "import os\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Data load\n",
    "df_co2 = pd.read_csv(\"https://raw.githubusercontent.com/owid/co2-data/master/owid-co2-data.csv\")\n",
    "df_energy = pd.read_csv(\"https://raw.githubusercontent.com/owid/energy-data/refs/heads/master/owid-energy-data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6d2e85",
   "metadata": {},
   "source": [
    "### Pre-processing the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78bd0b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'energy_per_capita', 'population', 'iso_code', 'primary_energy_consumption', 'gdp', 'year', 'energy_per_gdp', 'country'}\n"
     ]
    }
   ],
   "source": [
    "common_columns = set(df_co2.columns).intersection(set(df_energy.columns))\n",
    "print(common_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94d7ecae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# G20 countries\n",
    "g20_countries = [\n",
    "    'United States', 'China', 'Japan', 'Germany', \n",
    "    'United Kingdom', 'France', 'Italy', 'Canada',\n",
    "    'Brazil', 'Russia', 'India', 'Australia', \n",
    "    'Mexico', 'Indonesia', 'Turkey', 'Saudi Arabia',\n",
    "    'South Africa', 'Argentina', 'South Korea', 'Europe'\n",
    "]\n",
    "\n",
    "# Remove iso_code from the common columns\n",
    "common_cols = list(common_columns)\n",
    "common_cols.remove('iso_code')\n",
    "\n",
    "# Merge keys\n",
    "merge_keys = ['country', 'year']\n",
    "\n",
    "# Unique columns in each dataframe\n",
    "remain_common_cols = [col for col in common_cols if col not in merge_keys]\n",
    "df_co2_unique_cols = list(set(df_co2.columns) - set(df_energy.columns) - set(merge_keys))\n",
    "df_energy_unique_cols = list(set(df_energy.columns) - set(df_co2.columns) - set(merge_keys))\n",
    "overlap_cols = list(set(df_co2.columns).intersection(set(df_energy.columns)) - set(common_cols) - set(merge_keys))\n",
    "\n",
    "# Dataframe with unique rows\n",
    "df_co2_clean = df_co2.drop_duplicates(merge_keys)\n",
    "df_energy_clean = df_energy.drop_duplicates(merge_keys)\n",
    "\n",
    "# Merge common cols and unique cols\n",
    "col_co2 = remain_common_cols + df_co2_unique_cols\n",
    "col_energy = df_energy_unique_cols\n",
    "\n",
    "# Common cols appear once\n",
    "merged_df = pd.merge(\n",
    "    df_co2_clean[merge_keys + col_co2], \n",
    "    df_energy_clean[merge_keys + col_energy],\n",
    "    on=merge_keys, \n",
    "    how='outer'\n",
    ")\n",
    "\n",
    "# Overlapping cols not in common cols\n",
    "if overlap_cols:\n",
    "    for col in overlap_cols:\n",
    "        # Temp cols\n",
    "        co2_data = df_co2_clean[merge_keys + [col]].rename(columns={col: f\"{col}_co2\"})\n",
    "        energy_data = df_energy_clean[merge_keys + [col]].rename(columns={col: f\"{col}_energy\"})\n",
    "\n",
    "        merged_df = merged_df.merge(co2_data, on=merge_keys, how='left')\n",
    "        merged_df = merged_df.merge(energy_data, on=merge_keys, how='left')\n",
    "\n",
    "        merged_df[col] = merged_df[f\"{col}_co2\"].combine_first(merged_df[f\"{col}_energy\"])\n",
    "\n",
    "        # Drop temp cols\n",
    "        merged_df = merged_df.drop([f\"{col}_co2\", f\"{col}_energy\"], axis=1)\n",
    "\n",
    "df = merged_df.drop(['iso_code'], axis=1).copy()\n",
    "g20_df = df[df['country'].isin(g20_countries)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4319fffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Argentina', 'Australia', 'Brazil', 'Canada', 'China', 'Europe',\n",
       "       'France', 'Germany', 'India', 'Indonesia', 'Italy', 'Japan',\n",
       "       'Mexico', 'Russia', 'Saudi Arabia', 'South Africa', 'South Korea',\n",
       "       'Turkey', 'United Kingdom', 'United States'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g20_df['country'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b710783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time lag feature\n",
    "def time_lag_feature(df, feature_columns, periods=[1, 2, 3, 4]):\n",
    "    dup_df = df.copy()\n",
    "\n",
    "    if 'country' in dup_df.columns and 'year' in dup_df.columns:\n",
    "        dup_df = dup_df.sort_values(['country', 'year'])\n",
    "\n",
    "    for country, country_data in dup_df.groupby('country'):\n",
    "        for col in feature_columns:\n",
    "            if col in country_data.columns:\n",
    "                for lag in periods:\n",
    "                    lag_col_name = f\"{col}_lag{lag}\"\n",
    "                    dup_df.loc[country_data.index, lag_col_name] = country_data[col].shift(lag)\n",
    "\n",
    "    return dup_df\n",
    "\n",
    "lag_features = ['co2', 'gdp', 'population', 'primary_energy_consumption', 'fossil_fuel_consumption', 'renewables_consumption']\n",
    "\n",
    "lag_df = g20_df[['country', 'year'] + lag_features].copy()\n",
    "lag_df = time_lag_feature(lag_df, lag_features, [1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7771e96f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>co2</th>\n",
       "      <th>gdp</th>\n",
       "      <th>population</th>\n",
       "      <th>primary_energy_consumption</th>\n",
       "      <th>fossil_fuel_consumption</th>\n",
       "      <th>renewables_consumption</th>\n",
       "      <th>co2_lag1</th>\n",
       "      <th>co2_lag2</th>\n",
       "      <th>...</th>\n",
       "      <th>primary_energy_consumption_lag3</th>\n",
       "      <th>primary_energy_consumption_lag4</th>\n",
       "      <th>fossil_fuel_consumption_lag1</th>\n",
       "      <th>fossil_fuel_consumption_lag2</th>\n",
       "      <th>fossil_fuel_consumption_lag3</th>\n",
       "      <th>fossil_fuel_consumption_lag4</th>\n",
       "      <th>renewables_consumption_lag1</th>\n",
       "      <th>renewables_consumption_lag2</th>\n",
       "      <th>renewables_consumption_lag3</th>\n",
       "      <th>renewables_consumption_lag4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51601</th>\n",
       "      <td>United States</td>\n",
       "      <td>2022</td>\n",
       "      <td>5078.871</td>\n",
       "      <td>1.949317e+13</td>\n",
       "      <td>341534041.0</td>\n",
       "      <td>26504.305</td>\n",
       "      <td>21479.428</td>\n",
       "      <td>2993.056</td>\n",
       "      <td>5032.213</td>\n",
       "      <td>4714.628</td>\n",
       "      <td>...</td>\n",
       "      <td>26578.494</td>\n",
       "      <td>26768.986</td>\n",
       "      <td>21170.129</td>\n",
       "      <td>19936.998</td>\n",
       "      <td>21948.143</td>\n",
       "      <td>22212.854</td>\n",
       "      <td>2726.014</td>\n",
       "      <td>2590.245</td>\n",
       "      <td>2475.220</td>\n",
       "      <td>2399.240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51602</th>\n",
       "      <td>United States</td>\n",
       "      <td>2023</td>\n",
       "      <td>4911.391</td>\n",
       "      <td>NaN</td>\n",
       "      <td>343477332.0</td>\n",
       "      <td>26189.199</td>\n",
       "      <td>21102.201</td>\n",
       "      <td>3052.564</td>\n",
       "      <td>5078.871</td>\n",
       "      <td>5032.213</td>\n",
       "      <td>...</td>\n",
       "      <td>24622.646</td>\n",
       "      <td>26578.494</td>\n",
       "      <td>21479.428</td>\n",
       "      <td>21170.129</td>\n",
       "      <td>19936.998</td>\n",
       "      <td>21948.143</td>\n",
       "      <td>2993.056</td>\n",
       "      <td>2726.014</td>\n",
       "      <td>2590.245</td>\n",
       "      <td>2475.220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51603</th>\n",
       "      <td>United States</td>\n",
       "      <td>2024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4911.391</td>\n",
       "      <td>5078.871</td>\n",
       "      <td>...</td>\n",
       "      <td>25956.828</td>\n",
       "      <td>24622.646</td>\n",
       "      <td>21102.201</td>\n",
       "      <td>21479.428</td>\n",
       "      <td>21170.129</td>\n",
       "      <td>19936.998</td>\n",
       "      <td>3052.564</td>\n",
       "      <td>2993.056</td>\n",
       "      <td>2726.014</td>\n",
       "      <td>2590.245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             country  year       co2           gdp   population  \\\n",
       "51601  United States  2022  5078.871  1.949317e+13  341534041.0   \n",
       "51602  United States  2023  4911.391           NaN  343477332.0   \n",
       "51603  United States  2024       NaN           NaN          NaN   \n",
       "\n",
       "       primary_energy_consumption  fossil_fuel_consumption  \\\n",
       "51601                   26504.305                21479.428   \n",
       "51602                   26189.199                21102.201   \n",
       "51603                         NaN                      NaN   \n",
       "\n",
       "       renewables_consumption  co2_lag1  co2_lag2  ...  \\\n",
       "51601                2993.056  5032.213  4714.628  ...   \n",
       "51602                3052.564  5078.871  5032.213  ...   \n",
       "51603                     NaN  4911.391  5078.871  ...   \n",
       "\n",
       "       primary_energy_consumption_lag3  primary_energy_consumption_lag4  \\\n",
       "51601                        26578.494                        26768.986   \n",
       "51602                        24622.646                        26578.494   \n",
       "51603                        25956.828                        24622.646   \n",
       "\n",
       "       fossil_fuel_consumption_lag1  fossil_fuel_consumption_lag2  \\\n",
       "51601                     21170.129                     19936.998   \n",
       "51602                     21479.428                     21170.129   \n",
       "51603                     21102.201                     21479.428   \n",
       "\n",
       "       fossil_fuel_consumption_lag3  fossil_fuel_consumption_lag4  \\\n",
       "51601                     21948.143                     22212.854   \n",
       "51602                     19936.998                     21948.143   \n",
       "51603                     21170.129                     19936.998   \n",
       "\n",
       "       renewables_consumption_lag1  renewables_consumption_lag2  \\\n",
       "51601                     2726.014                     2590.245   \n",
       "51602                     2993.056                     2726.014   \n",
       "51603                     3052.564                     2993.056   \n",
       "\n",
       "       renewables_consumption_lag3  renewables_consumption_lag4  \n",
       "51601                     2475.220                     2399.240  \n",
       "51602                     2590.245                     2475.220  \n",
       "51603                     2726.014                     2590.245  \n",
       "\n",
       "[3 rows x 32 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lag_df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccd2293e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for RMSE\n",
    "def rmse(pred, actual):\n",
    "    return np.sqrt(((pred - actual)**2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a55205e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split sequence for train\n",
    "def split_sequence(sequences, n_steps_in, n_steps_out):\n",
    "    X, y = [], []\n",
    "    for i in range(len(sequences)):\n",
    "        # End of the pattern\n",
    "        end_idx = i + n_steps_in\n",
    "        out_end_idx = end_idx + n_steps_out\n",
    "\n",
    "        # Checking if its beyond the dataset\n",
    "        if out_end_idx > len(sequences):\n",
    "            break\n",
    "\n",
    "        # Gathering input and output parts of the pattern\n",
    "        seq_x, seq_y = sequences.iloc[i:end_idx, :], sequences.iloc[end_idx:out_end_idx, :]\n",
    "        X.append(seq_x.values)\n",
    "        y.append(seq_y.values)\n",
    "\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f700770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to reshape seq for pred\n",
    "def reshape_sequence(sequence, n_steps_in):\n",
    "    X = []\n",
    "    for i in range(len(sequence)):\n",
    "        # End of the pattern\n",
    "        end_idx = i + n_steps_in\n",
    "\n",
    "        # Checking if its beyond the seq\n",
    "        if end_idx > len(sequence):\n",
    "            break\n",
    "\n",
    "        # Gathering input parts of the pattern\n",
    "        seq_x = sequence[i:end_idx, :]\n",
    "        X.append(seq_x)\n",
    "\n",
    "    return np.array(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb520853",
   "metadata": {},
   "source": [
    "### Modified function to add validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4747e00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create shuffled train/test sets with validation set\n",
    "def shuffled_test_train_val(n_inp, n_out, df, test_size=0.2, val_size=0.1):\n",
    "    from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "    # Batches\n",
    "    batches = []\n",
    "    for i in range(len(df)):\n",
    "        if (i + n_inp + n_out > len(df)):\n",
    "            break\n",
    "        batches.append(df.iloc[i:i + n_inp + n_out].values)\n",
    "\n",
    "    rs = ShuffleSplit(n_splits=1, test_size=test_size, random_state=42)\n",
    "\n",
    "    # First split for train val and test\n",
    "    for train_val_ind, test_ind in rs.split(batches):\n",
    "        print(f\"Train & Val: {len(train_val_ind)} samples, Test: {len(test_ind)} samples.\")\n",
    "        break\n",
    "\n",
    "    # Second split for train and val\n",
    "    train_val_batches = [batches[i] for i in train_val_ind]\n",
    "    rs_val = ShuffleSplit(n_splits=1, test_size=val_size/(1-test_size), random_state=42)\n",
    "\n",
    "    for train_ind, val_ind in rs_val.split(train_val_batches):\n",
    "        print(f\"Train: {len(train_ind)} samples, Val: {len(val_ind)} samples.\")\n",
    "\n",
    "    # Final Split\n",
    "    train = np.array([train_val_batches[i] for i in train_ind])\n",
    "    val = np.array([train_val_batches[i] for i in val_ind])\n",
    "    test = np.array([batches[i] for i in test_ind])\n",
    "\n",
    "    X_train = train[:, :n_inp, :]\n",
    "    y_train = train[:, n_inp:, :]\n",
    "\n",
    "    X_val = val[:, :n_inp, :]\n",
    "    y_val = val[:, n_inp:, :]\n",
    "    \n",
    "    X_test = test[:, :n_inp, :]\n",
    "    y_test = test[:, n_inp:, :]\n",
    "\n",
    "    return train, val, test, X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd76160",
   "metadata": {},
   "source": [
    "## 2. The second experiment\n",
    "### Which ML model to choose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbde871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. LSTM model\n",
    "def lstm_model(n_steps_in, n_features, n_steps_out, hidden=16):\n",
    "    model = Sequential([\n",
    "        LSTM(hidden, activation='relu', input_shape=(n_steps_in, n_features)),\n",
    "        Dense(n_steps_out)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929e0621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Bi-directional LSTM model\n",
    "def bilstm_model(n_steps_in, n_features, n_steps_out, hidden=16):\n",
    "    model = Sequential([\n",
    "        Bidirectional(LSTM(hidden, activation='relu'), input_shape=(n_steps_in, n_features)),\n",
    "        Dense(n_steps_out)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5979d467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. CNN model\n",
    "def cnn_model(n_steps_in, n_features, n_steps_out, hidden=16):\n",
    "    model = Sequential([\n",
    "        Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps_in, n_features))\n",
    "    ])\n",
    "    \n",
    "    if n_steps_in > 3:\n",
    "        model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(hidden, activation='relu'))\n",
    "    model.add(Dense(n_steps_out))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a577a2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. ED LSTM model\n",
    "def edlstm_model(n_steps_in, n_features, n_steps_out, hidden=16):\n",
    "    model = Sequential([\n",
    "        LSTM(hidden, activation='relu', input_shape=(n_steps_in, n_features)),\n",
    "        RepeatVector(n_steps_out),\n",
    "        LSTM(hidden, activation='relu', return_sequences=True),\n",
    "        TimeDistributed(Dense(1))\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e831fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_types = {\n",
    "    'LSTM': lstm_model,\n",
    "    'Bi-LSTM': bilstm_model,\n",
    "    'CNN': cnn_model,\n",
    "    'ED-LSTM': edlstm_model\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8156b891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the best model\n",
    "def find_best_model(feature_data, target_feature, n_steps_in=5, n_steps_out=1, models_to_test=None, epochs=20):\n",
    "    if models_to_test is None:\n",
    "        models_to_test = list(model_types.keys())\n",
    "\n",
    "    print(f\"\\nTesting models for {target_feature}\")\n",
    "    print(f\"Data shape: {feature_data.shape}\")\n",
    "\n",
    "    if len(feature_data) < n_steps_in + n_steps_out + 10:\n",
    "        print(f\"Not enough data for {target_feature}\")\n",
    "        return None\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_data = feature_data.copy()\n",
    "    for col in scaled_data.columns:\n",
    "        if col not in ['country', 'year']:\n",
    "                scaled_data[col] = scaler.fit_transform(scaled_data[col].values.reshape(-1, 1))\n",
    "\n",
    "    model_data = scaled_data.select_dtypes(include=np.number)\n",
    "\n",
    "    train, val, test, X_train, y_train, X_val, y_val, X_test, y_test = shuffled_test_train_val(\n",
    "        n_steps_in, n_steps_out, model_data)\n",
    "    \n",
    "    target_ind = list(model_data.columns).index(target_feature)\n",
    "\n",
    "    y_train_target = y_train[:, :, target_ind].reshape(-1, n_steps_out)\n",
    "    y_val_target = y_val[:, :, target_ind].reshape(-1, n_steps_out)\n",
    "    y_test_target = y_test[:, :, target_ind].reshape(-1, n_steps_out)\n",
    "\n",
    "    n_features = X_train.shape[2]\n",
    "    best_model = None\n",
    "    best_rmse = float('inf')\n",
    "    best_model_name = None\n",
    "    model_results = {}\n",
    "\n",
    "    for model_name in models_to_test:\n",
    "        print(f\"Test {model_name}\")\n",
    "\n",
    "        model = model_types[model_name](n_steps_in, n_features, n_steps_out)\n",
    "\n",
    "        # Additional modification for ED LSTM model\n",
    "        if model_name == 'ED-LSTM':\n",
    "            y_train_reshaped = y_train_target.reshape(y_train_target.shape[0], y_train_target.shape[1], 1)\n",
    "            y_val_reshaped = y_val_target.reshape(y_val_target.shape[0], y_val_target.shape[1], 1)\n",
    "\n",
    "            history = model.fit(\n",
    "                X_train, y_train_reshaped,\n",
    "                epochs=epochs, batchsize=32, verbose=0, validation_data=(X_val, y_val_reshaped),\n",
    "                callbacks=[EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)]\n",
    "            )\n",
    "            val_pred = model.predict(X_val)\n",
    "            val_pred = np.squeeze(val_pred, axis=2)\n",
    "\n",
    "        else:\n",
    "            history = model.fit(\n",
    "                X_train, y_train_target,\n",
    "                epochs=epochs, batchsize=32, verbose=0, validation_data=(X_val, y_val_target),\n",
    "                callbacks=[EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)]\n",
    "            )\n",
    "            val_pred = model.predict(X_val)\n",
    "\n",
    "        val_rmse = rmse(val_pred, y_val_target)\n",
    "        model_results[model_name] = val_rmse\n",
    "\n",
    "        print(f\"{model_name} - validation RMSE: {val_rmse:.4f}\")\n",
    "\n",
    "        if val_rmse < best_rmse:\n",
    "            best_rmse = val_rmse\n",
    "            best_model = model\n",
    "            best_model_name = model_name\n",
    "\n",
    "    return {\n",
    "        'best_model': best_model,\n",
    "        'best_model_name': best_model_name,\n",
    "        'best_rmse': best_rmse,\n",
    "        'model_results': model_results,\n",
    "        'target_feature': target_feature\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0c843f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the best model for each feature\n",
    "def run_best_model_for_feature(country, target_features=None, start_year=1960, n_steps_in=5, n_steps_out=1):\n",
    "    \n",
    "    print(f\"Running Best Model for {country.upper()}\")\n",
    "\n",
    "    country_data = g20_df[g20_df['country'] == country].copy()\n",
    "    country_data = country_data[country_data['year'] >= start_year].copy()\n",
    "\n",
    "    if target_features is None:\n",
    "        target_features = ['co2', 'gdp', 'primary_energy_consumption']\n",
    "\n",
    "    avail_features = [f for f in target_features if f in country_data.columns]\n",
    "    best_models = {}\n",
    "\n",
    "    for feature in avail_features:\n",
    "        print(f\"Find best model for {feature}\")\n",
    "        numerical_features = [f for f in country_data.columns \n",
    "                              if f not in ['country', 'year'] and country_data[f].dtype in ['float64', 'int64']]\n",
    "        \n",
    "        feature_data = country_data[['year'] + numerical_features].copy()\n",
    "        feature_data = feature_data.dropna()\n",
    "\n",
    "        result = find_best_model(feature_data, feature, n_steps_in, n_steps_out)\n",
    "        best_models[feature] = result\n",
    "        print(f\"Best model for {feature}: {result['best_model_name']} (RMSE: {result['best_rmse']:.4f})\")\n",
    "    \n",
    "    return best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c3d696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model\n",
    "def save_model(best_models, country, filepath='C:\\Users\\sodjs\\RL/'):\n",
    "    if not os.path.exists(filepath):\n",
    "        os.makedirs(filepath)\n",
    "\n",
    "    models = {}\n",
    "    for feature, model_result in best_models.items():\n",
    "        model_path = f\"{filepath}{country}_{feature}_model.h5\"\n",
    "        model_result['best_model'].save(model_path)\n",
    "\n",
    "        models[feature] = {\n",
    "            'model_path': model_path,\n",
    "            'model_name': model_result['best_model_name'],\n",
    "            'rmse': model_result['best_rmse'],\n",
    "            'target_feature': model_result['target_feature']\n",
    "        }\n",
    "\n",
    "    with open(f\"{filepath}{country}_model_result.pk1\", 'wb') as f:\n",
    "        pickle.dump(models, f)\n",
    "\n",
    "    print(f\"Saved model for {country}\")\n",
    "    return models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
