{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6fac95f",
   "metadata": {},
   "source": [
    "# Leave One Country Out vs Single country\n",
    "## Using one target and its lags\n",
    "### This version is applied country-specific normalisation instead of normalising for all countries.\n",
    "### The model is trained with the features, the feature's time lags, designated target, and the target's time lags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156414be",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f21ddd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import gc\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Bidirectional, Input, Concatenate, Embedding\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, RepeatVector, TimeDistributed\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad814fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Configuration\n",
    "TARGET_VARIABLES = ['co2', 'gdp', 'primary_energy_consumption']\n",
    "N_STEPS_IN = 5\n",
    "N_STEPS_OUT = 3\n",
    "# Setting test size as 9 samples\n",
    "TEST_SAMPLES = 9\n",
    "MAX_LAGS = 4\n",
    "\n",
    "G20_COUNTRIES = [\n",
    "    'United States', 'China', 'Japan', 'Germany', \n",
    "    'United Kingdom', 'France', 'Italy', 'Canada',\n",
    "    'Brazil', 'Russia', 'India', 'Australia', \n",
    "    'Mexico', 'Indonesia', 'Turkey', 'Saudi Arabia',\n",
    "    'South Africa', 'Argentina', 'South Korea'\n",
    "]\n",
    "\n",
    "FEATURES = [\n",
    "    'fossil_fuel_consumption', 'energy_per_capita',\n",
    "    'electricity_generation', 'population',\n",
    "    'nuclear_consumption', 'renewables_consumption'\n",
    "]\n",
    "\n",
    "DEVELOPED_COUNTRIES = [\n",
    "    'United States', 'Japan', 'Germany', 'United Kingdom',\n",
    "    'France', 'Italy', 'Canada', 'Australia', 'South Korea'\n",
    "]\n",
    "\n",
    "DEVELOPING_COUNTRIES = [\n",
    "    'China', 'Brazil', 'Russia', 'India', 'Mexico', 'Indonesia',\n",
    "    'Turkey', 'Saudi Arabia', 'South Africa', 'Argentina'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b707cc",
   "metadata": {},
   "source": [
    "### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341cf27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_memory():\n",
    "    tf.keras.backend.clear_session()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a087c1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_pred, y_actual):\n",
    "    return np.sqrt(mean_squared_error(y_actual, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4b9cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mase(y_actual, y_pred, period=1):\n",
    "\n",
    "    mae_forecast = mean_absolute_error(y_actual, y_pred)\n",
    "    \n",
    "    # MAE of naive forecast\n",
    "    naive_forecast = y_actual[:-period] if period > 0 else y_actual[:-1]\n",
    "    actual_for_naive = y_actual[period:] if period > 0 else y_actual[1:]\n",
    "    \n",
    "    if len(naive_forecast) == 0:\n",
    "        return np.nan\n",
    "    \n",
    "    mae_naive = mean_absolute_error(actual_for_naive, naive_forecast)\n",
    "    \n",
    "    if mae_naive == 0:\n",
    "        return 0 if mae_forecast == 0 else np.inf\n",
    "    \n",
    "    return mae_forecast / mae_naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57db226a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pct_change_features(data):\n",
    "    \"\"\"\n",
    "    This is to convert the series into the percentage change from the previous time step\n",
    "    -> It will lead the data more stationary\n",
    "    Avoiding NaN in the first row\n",
    "    \"\"\"\n",
    "    data = data.copy()\n",
    "\n",
    "    # For each feature, calculate pct_change with lag1\n",
    "    for feature in FEATURES + TARGET_VARIABLES:\n",
    "        if feature in data.columns:\n",
    "            # Store original values\n",
    "            data[f'{feature}_original'] = data[feature].values.copy()\n",
    "            \n",
    "            # pct_change\n",
    "            if f'{feature}_lag1' in data.columns:\n",
    "                lag1_values = data[f'{feature}_lag1'].values\n",
    "                current_values = data[feature].values\n",
    "\n",
    "                # Create mask for non-zero lag values\n",
    "                non_zero_mask = lag1_values != 0\n",
    "                pct_change = np.zeros_like(current_values)\n",
    "            \n",
    "                # Calculate pct change only where lag1 is non-zero (curr - lag1) / lag1\n",
    "                pct_change[non_zero_mask] = (current_values[non_zero_mask] - lag1_values[non_zero_mask]) / lag1_values[non_zero_mask]\n",
    "                \n",
    "                data[f'{feature}_pct'] = pct_change\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea6d816",
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalise_pct_change(pct_preds, last_actual_value):\n",
    "    \"\"\"\n",
    "    Conver pct_change preds back to the original scale\n",
    "    value_t = value_{t-1} * (1 + pct_change_t)\n",
    "    \"\"\"\n",
    "    actual_values = []\n",
    "    curr_val = last_actual_value\n",
    "    \n",
    "    for pct in pct_preds:\n",
    "        next_value = curr_val * (1 + pct)\n",
    "        actual_values.append(next_value)\n",
    "        curr_val = next_value\n",
    "    \n",
    "    return np.array(actual_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553b6de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features_target_time_lags(data, features, target, use_lags=True):\n",
    "    \"\"\"\n",
    "    Preparing feature matrix with time lag features and the designated target (including target as a feature)\n",
    "    This is to let the model see the target's historical values\n",
    "    \"\"\"\n",
    "    feature_cols = []\n",
    "\n",
    "    all_features_with_target = features.copy()\n",
    "    if target not in all_features_with_target:\n",
    "        all_features_with_target.append(target)\n",
    "\n",
    "    for feature in all_features_with_target:\n",
    "        if f'{feature}_pct' in data.columns:\n",
    "            feature_cols.append(f'{feature}_pct')\n",
    "        elif feature in data.columns:\n",
    "            feature_cols.append(feature)\n",
    "        \n",
    "        if use_lags:\n",
    "            for lag in range(1, MAX_LAGS+1):\n",
    "                lag_col = f'{feature}_lag{lag}'\n",
    "\n",
    "                if lag_col in data.columns:\n",
    "                    if lag < MAX_LAGS:\n",
    "                        next_lag = f'{feature}_lag{lag+1}'\n",
    "                        if next_lag in data.columns:\n",
    "                            lag_values = data[lag_col].values\n",
    "                            next_lag_values = data[next_lag].values\n",
    "\n",
    "                            non_zero_mask = next_lag_values != 0\n",
    "                            pct_lag = np.zeros_like(lag_values)\n",
    "                            pct_lag[non_zero_mask] = (lag_values[non_zero_mask] - next_lag_values[non_zero_mask]) / next_lag_values[non_zero_mask]\n",
    "\n",
    "                            pct_lag_col = f'{feature}_lag{lag}_pct'\n",
    "                            data[pct_lag_col] = pct_lag\n",
    "                            feature_cols.append(pct_lag_col)\n",
    "                    else:\n",
    "                        if f'{feature}_lag{lag}_pct' in data.columns:\n",
    "                            feature_cols.append(f'{feature}_lag{lag}_pct')\n",
    "                        elif lag_col in data.columns:\n",
    "                            feature_cols.append(lag_col)\n",
    "\n",
    "    if f'{target}_pct' in data.columns:\n",
    "        target_col = f'{target}_pct'\n",
    "    else:\n",
    "        target_col = target\n",
    "\n",
    "    # Removing duplicates and preserve the order\n",
    "    shown = set()\n",
    "    feature_cols_unique = []\n",
    "    for col in feature_cols:\n",
    "        if col not in shown:\n",
    "            shown.add(col)\n",
    "            feature_cols_unique.append(col)\n",
    "    \n",
    "    return data, feature_cols_unique, target_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0309269",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features(data, features, target, use_lags=True):\n",
    "    \"\"\"\n",
    "    Preparing feature matrix with lag features and pct changes\n",
    "    \"\"\"\n",
    "    feature_cols = []\n",
    "\n",
    "    all_features = features.copy()\n",
    "    if target not in all_features:\n",
    "        all_features.append(target)\n",
    "\n",
    "    for feature in all_features:\n",
    "        # Use the original column\n",
    "        if feature in data.columns:\n",
    "            feature_cols.append(feature)\n",
    "        # Or use the _pct column if it exists\n",
    "        elif f'{feature}_pct' in data.columns:\n",
    "            feature_cols.append(f'{feature}_pct')\n",
    "\n",
    "        # Lag features\n",
    "        if use_lags:\n",
    "            for lag in range(1, 5):\n",
    "                lag_col = f'{feature}_lag{lag}'\n",
    "\n",
    "                if lag_col in data.columns:\n",
    "                    # Calculate pct change for lag features\n",
    "                    if lag < 4:\n",
    "                        next_lag = f'{feature}_lag{lag+1}'\n",
    "                        if next_lag in data.columns:\n",
    "                            lag_values = data[lag_col].values\n",
    "                            next_lag_values = data[next_lag].values\n",
    "                            \n",
    "                            non_zero_mask = next_lag_values != 0\n",
    "                            pct_lag = np.zeros_like(lag_values)\n",
    "                            pct_lag[non_zero_mask] = (lag_values[non_zero_mask] - next_lag_values[non_zero_mask]) / next_lag_values[non_zero_mask]\n",
    "                            \n",
    "                            pct_lag_col = f'{feature}_lag{lag}_pct'\n",
    "                            data[pct_lag_col] = pct_lag\n",
    "                            feature_cols.append(pct_lag_col)\n",
    "    \n",
    "    if f'{target}_pct' in data.columns:\n",
    "        target_col = f'{target}_pct'\n",
    "    else:\n",
    "        target_col = target\n",
    "    \n",
    "    return data, feature_cols, target_col"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb45b49",
   "metadata": {},
   "source": [
    "### Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75b9a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(save_dir='data_export'):\n",
    "    lag_path = os.path.join(save_dir, 'lag_df_1965.pkl')\n",
    "    lag_df = pd.read_pickle(lag_path)\n",
    "    print(f\"Data Shape: {lag_df.shape}\")\n",
    "    return lag_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7829ecd4",
   "metadata": {},
   "source": [
    "### Model builds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e700e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm(input_shape, output_shape, hidden=32):\n",
    "    model = Sequential([\n",
    "        LSTM(hidden, activation='relu', input_shape=input_shape, kernel_regularizer=l2(0.01)),\n",
    "        Dense(output_shape)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.01), loss='mse', metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c98f964",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_bilstm(input_shape, output_shape, hidden=16):\n",
    "    model = Sequential([\n",
    "        Bidirectional(LSTM(hidden, activation='relu', kernel_regularizer=l2(0.001), recurrent_regularizer=l2(0.01)),\n",
    "                      input_shape=input_shape),\n",
    "        Dense(output_shape)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.01), loss='mse', metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f402484b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_edlstm(input_shape, output_shape, hidden=16):\n",
    "    model = Sequential([\n",
    "        LSTM(hidden, activation='relu', input_shape=input_shape, kernel_regularizer=l2(0.01)),\n",
    "        RepeatVector(output_shape),\n",
    "        LSTM(hidden, activation='relu', return_sequences=True, kernel_regularizer=l2(0.01)),\n",
    "        TimeDistributed(Dense(1))\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.01), loss='mse', metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30b625c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn(input_shape, output_shape, filters=32, hidden=16):\n",
    "    model = Sequential([\n",
    "        Conv1D(filters=filters, kernel_size=3, activation='relu', input_shape=input_shape, padding='same', kernel_regularizer=l2(0.01)),\n",
    "        Flatten(),\n",
    "        Dense(hidden, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        Dense(output_shape)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.01), loss='mse', metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4d129c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_multioutput_model(input_shape, n_features, output_steps, hidden=16):\n",
    "    \"\"\"\n",
    "    This model predicts both Y and X features\n",
    "    \"\"\"\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    # LSTM process\n",
    "    lstm_out = LSTM(hidden, activation='relu', return_sequences=False)(inputs)\n",
    "\n",
    "    # Output for target\n",
    "    y_output = Dense(output_steps, name='y_output')(lstm_out)\n",
    "\n",
    "    # Output for features\n",
    "    x_output_flat = Dense(output_steps * n_features, name='x_output')(lstm_out)\n",
    "    x_output = tf.keras.layers.Reshape((output_steps, n_features), name='x_reshape')(x_output_flat)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=[y_output, x_output])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.01),\n",
    "        loss={'y_output': 'mse', 'x_output': 'mse'},\n",
    "        loss_weights={'y_output': 1.0, 'x_output': 0.5}, # More weights for y_output\n",
    "        metrics={'y_output': 'mae', 'x_output': 'mae'}\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8df68f",
   "metadata": {},
   "source": [
    "### LOCO with Single target\n",
    "Leave One Country Out with the designated single target lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b70944f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleTargetLOCOForecaster:\n",
    "    def __init__(self, model_func, input_steps=N_STEPS_IN, output_steps=N_STEPS_OUT):\n",
    "        self.model_func = model_func\n",
    "        self.input_steps = input_steps\n",
    "        self.output_steps = output_steps\n",
    "        self.model = None\n",
    "        self.country_scalers = {}\n",
    "        self.is_trained = False\n",
    "        self.n_features = None\n",
    "\n",
    "    def create_sequences(self, X, y):\n",
    "        if len(X) < self.input_steps + self.output_steps:\n",
    "            return np.array([]), np.array([])\n",
    "        \n",
    "        X_seq = []\n",
    "        y_seq = []\n",
    "\n",
    "        for i in range(len(X) - self.input_steps - self.output_steps + 1):\n",
    "            X_seq.append(X[i:i + self.input_steps])\n",
    "            y_seq.append(y[i + self.input_steps:i + self.input_steps + self.output_steps])\n",
    "        \n",
    "        X_seq = np.array(X_seq)\n",
    "        y_seq = np.array(y_seq)\n",
    "\n",
    "        if len(X_seq) > 0 and len(X_seq.shape) == 2:\n",
    "            X_seq = X_seq.reshape(len(X_seq), self.input_steps, -1)\n",
    "\n",
    "        if len(y_seq) > 0 and len(y_seq.shape) == 1:\n",
    "            y_seq = y_seq.reshape(len(y_seq), self.output_steps)\n",
    "        \n",
    "        return X_seq, y_seq\n",
    "    \n",
    "    def train_model(self, X_train_pct_dict, y_train_pct_dict, countries_train):\n",
    "        \"\"\"\"\n",
    "        Training with country-specific normalisation\n",
    "        \"\"\"\n",
    "        X_train_scaled_list = []\n",
    "        y_train_scaled_list = []\n",
    "        \n",
    "        for country in countries_train:\n",
    "            if country not in X_train_pct_dict or country not in y_train_pct_dict:\n",
    "                continue\n",
    "                \n",
    "            X_country_pct = X_train_pct_dict[country]\n",
    "            y_country_pct = y_train_pct_dict[country]\n",
    "            \n",
    "            if len(X_country_pct) == 0:\n",
    "                continue\n",
    "\n",
    "            # Country-specific scalers\n",
    "            scaler_X = StandardScaler()\n",
    "            scaler_y = StandardScaler()\n",
    "            \n",
    "            X_scaled = scaler_X.fit_transform(X_country_pct)\n",
    "            y_scaled = scaler_y.fit_transform(y_country_pct.reshape(-1, 1)).ravel()\n",
    "            \n",
    "            self.country_scalers[country] = {\n",
    "                'X_scaler': scaler_X,\n",
    "                'y_scaler': scaler_y\n",
    "            }\n",
    "            \n",
    "            X_train_scaled_list.append(X_scaled)\n",
    "            y_train_scaled_list.append(y_scaled)\n",
    "        \n",
    "        X_train_combined = np.vstack(X_train_scaled_list)\n",
    "        y_train_combined = np.hstack(y_train_scaled_list)\n",
    "        \n",
    "        self.n_features = X_train_combined.shape[1]\n",
    "        \n",
    "        X_train_seq, y_train_seq = self.create_sequences(X_train_combined, y_train_combined)\n",
    "        \n",
    "        if len(X_train_seq) == 0:\n",
    "            print(\"Not enough data to create sequences\")\n",
    "            return\n",
    "        \n",
    "        print(f\"Training seq: {len(X_train_seq)}\")\n",
    "        print(f\"Feature dim: {self.n_features}\")\n",
    "\n",
    "        input_shape = (self.input_steps, self.n_features)\n",
    "        self.model = self.model_func(input_shape, self.output_steps)\n",
    "\n",
    "        callbacks = [EarlyStopping(monitor='loss', patience=20, restore_best_weights=True)]\n",
    "\n",
    "        batch_size = min(16, len(X_train_seq))\n",
    "        \n",
    "        self.model.fit(\n",
    "            X_train_seq, y_train_seq,\n",
    "            epochs=100,\n",
    "            batch_size=batch_size,\n",
    "            callbacks=callbacks,\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "        self.is_trained = True\n",
    "\n",
    "    def calculate_metrics(self, predictions, actuals, iteration_num):\n",
    "        if len(predictions) == 0 or len(actuals) == 0:\n",
    "            return {'iteration': iteration_num, 'rmse': np.nan, 'mase': np.nan}\n",
    "        \n",
    "        rmse_val = rmse(predictions, actuals)\n",
    "        mase_val = mase(actuals, predictions)\n",
    "        return {'iteration': iteration_num, 'rmse': rmse_val, 'mase': mase_val}\n",
    "    \n",
    "    def forecast(self, X_train_pct, y_train_pct, X_test_pct, y_test_pct, target_country, \n",
    "                 y_train_original=None, y_test_original=None):\n",
    "        if not self.is_trained:\n",
    "            print(\"Model not trained\")\n",
    "            return None\n",
    "        \n",
    "        if target_country in self.country_scalers:\n",
    "            scaler_X = self.country_scalers[target_country]['X_scaler']\n",
    "            scaler_y = self.country_scalers[target_country]['y_scaler']\n",
    "        else:\n",
    "            scaler_X = StandardScaler()\n",
    "            scaler_y = StandardScaler()\n",
    "            scaler_X.fit(X_train_pct)\n",
    "            scaler_y.fit(y_train_pct.reshape(-1, 1))\n",
    "            self.country_scalers[target_country] = {\n",
    "                'X_scaler': scaler_X,\n",
    "                'y_scaler': scaler_y\n",
    "            }\n",
    "        \n",
    "        X_train_scaled = scaler_X.transform(X_train_pct)\n",
    "        X_test_scaled = scaler_X.transform(X_test_pct)\n",
    "        \n",
    "        predictions_pct = []\n",
    "        actuals_pct = []\n",
    "        predictions_actual = []\n",
    "        actuals_actual = []\n",
    "        iterations = []\n",
    "        metrics_list = []\n",
    "\n",
    "        for iteration in range(3):\n",
    "            if iteration == 0:\n",
    "                X_window = X_train_scaled[-5:]\n",
    "                start_idx = 0\n",
    "                print(f\"    Iter {iteration}: Using last 5 train values\")\n",
    "            elif iteration == 1:\n",
    "                X_window = np.vstack([X_train_scaled[-2:], X_test_scaled[0:3]])\n",
    "                start_idx = 3\n",
    "                print(f\"    Iter {iteration}: Using last 2 train + test[0:3]\")\n",
    "            elif iteration == 2:\n",
    "                X_window = X_test_scaled[1:6]\n",
    "                start_idx = 6\n",
    "                print(f\"    Iter {iteration}: Using test[1:6]\")\n",
    "\n",
    "            X_input = X_window.reshape(1, self.input_steps, -1)\n",
    "\n",
    "            y_pred_scaled = self.model.predict(X_input, verbose=0)\n",
    "            y_pred_scaled = y_pred_scaled.flatten()\n",
    "\n",
    "            # Inverse scale back to pct_change\n",
    "            y_pred_pct = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).ravel()\n",
    "\n",
    "            end_idx = min(start_idx + self.output_steps, len(y_test_pct))\n",
    "            y_actual_pct = y_test_pct[start_idx:end_idx]\n",
    "\n",
    "            # Convert back to original values\n",
    "            if y_test_original is not None and y_train_original is not None:\n",
    "                if iteration == 0:\n",
    "                    last_known_value = y_train_original[-1]\n",
    "                else:\n",
    "                    last_known_value = y_test_original[start_idx - 1]\n",
    "\n",
    "                y_pred_actual = denormalise_pct_change(y_pred_pct[:len(y_actual_pct)], last_known_value)\n",
    "                y_actual_actual = y_test_original[start_idx:end_idx]\n",
    "\n",
    "                if len(y_actual_actual) == len(y_pred_actual):\n",
    "                    predictions_actual.extend(y_pred_actual)\n",
    "                    actuals_actual.extend(y_actual_actual)\n",
    "\n",
    "                    metrics = self.calculate_metrics(y_pred_actual, y_actual_actual, iteration)\n",
    "                else:\n",
    "                    metrics = self.calculate_metrics(y_pred_pct[:len(y_actual_pct)], y_actual_pct, iteration)\n",
    "            else:\n",
    "                metrics = self.calculate_metrics(y_pred_pct[:len(y_actual_pct)], y_actual_pct, iteration)\n",
    "            \n",
    "            predictions_pct.extend(y_pred_pct[:len(y_actual_pct)])\n",
    "            actuals_pct.extend(y_actual_pct)\n",
    "            iterations.extend([iteration] * len(y_actual_pct))\n",
    "            metrics_list.append(metrics)\n",
    "            print(f\"    RMSE: {metrics['rmse']:.4f}, MASE: {metrics['mase']:.4f}\")\n",
    "        \n",
    "        results = {\n",
    "            'predictions_pct': np.array(predictions_pct),\n",
    "            'actuals_pct': np.array(actuals_pct),\n",
    "            'iterations': np.array(iterations),\n",
    "            'metrics': pd.DataFrame(metrics_list)\n",
    "        }\n",
    "\n",
    "        if len(predictions_actual) > 0:\n",
    "            results['predictions_actual'] = np.array(predictions_actual)\n",
    "            results['actuals_actual'] = np.array(actuals_actual)\n",
    "        \n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea6d4ac",
   "metadata": {},
   "source": [
    "### Single Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a3e136",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleTargetLOCOComparison:\n",
    "    def __init__(self, countries, features, target):\n",
    "        self.countries = countries\n",
    "        self.features = features\n",
    "        self.target = target\n",
    "\n",
    "    def run_comparison(self, data, test_country, model_func=build_lstm):\n",
    "        print(f\"Single Target LOCO for: {test_country}\")\n",
    "        print(f\"Target: {self.target} + its lags\")\n",
    "\n",
    "        # Applying pct change normalisation to all data\n",
    "        data = pct_change_features(data)\n",
    "        \n",
    "        train_countries = [c for c in self.countries if c != test_country]\n",
    "        \n",
    "        X_train_pct_dict = {}\n",
    "        y_train_pct_dict = {}\n",
    "        \n",
    "        for country in train_countries:\n",
    "            country_data = data[data['country'] == country].sort_values('year')\n",
    "\n",
    "            # Prepare features -> all to be pct change\n",
    "            country_data, feature_cols, target_col = prepare_features_target_time_lags(\n",
    "                country_data, self.features, self.target, use_lags=True\n",
    "            )\n",
    "            \n",
    "            original_target_col = f'{self.target}_original'\n",
    "            \n",
    "            valid_cols = feature_cols + [target_col]\n",
    "            if original_target_col in country_data.columns:\n",
    "                valid_cols.append(original_target_col)\n",
    "            \n",
    "            valid_data = country_data[valid_cols].dropna()\n",
    "            \n",
    "            if len(valid_data) > 0:\n",
    "                X_pct = valid_data[feature_cols].values\n",
    "                y_pct = valid_data[target_col].values\n",
    "                \n",
    "                X_train_pct_dict[country] = X_pct\n",
    "                y_train_pct_dict[country] = y_pct\n",
    "\n",
    "        if len(X_train_pct_dict) == 0:\n",
    "            print(\"No training data available\")\n",
    "            return None\n",
    "        \n",
    "        print(f\"Training data from {len(X_train_pct_dict)} countries\")\n",
    "\n",
    "        # Test country data\n",
    "        test_data = data[data['country'] == test_country].sort_values('year')\n",
    "        test_data, feature_cols, target_col = prepare_features_target_time_lags(\n",
    "            test_data, self.features, self.target, use_lags=True\n",
    "            )\n",
    "        \n",
    "        original_target_col = f'{self.target}_original'\n",
    "        test_valid_cols = feature_cols + [target_col]\n",
    "        if original_target_col in test_data.columns:\n",
    "            test_valid_cols.append(original_target_col)\n",
    "        \n",
    "        test_valid = test_data[test_valid_cols].dropna()\n",
    "        \n",
    "        if len(test_valid) == 0:\n",
    "            print(f\"No valid data for {test_country}\")\n",
    "            return None\n",
    "        \n",
    "        n_test_country_samples = len(test_valid)\n",
    "        n_test = TEST_SAMPLES\n",
    "        n_train = n_test_country_samples - n_test\n",
    "        \n",
    "        if n_train < N_STEPS_IN:\n",
    "            print(f\"Not enough training data for {test_country}\")\n",
    "            return None\n",
    "        \n",
    "        X_test_country_pct = test_valid[feature_cols].values\n",
    "        y_test_country_pct = test_valid[target_col].values\n",
    "        y_test_country_original = test_valid[original_target_col].values if original_target_col in test_valid.columns else None\n",
    "        \n",
    "        X_train_from_test_pct = X_test_country_pct[:n_train]\n",
    "        y_train_from_test_pct = y_test_country_pct[:n_train]\n",
    "        y_train_from_test_original = y_test_country_original[:n_train] if y_test_country_original is not None else None\n",
    "        \n",
    "        X_test_pct = X_test_country_pct[n_train:n_train + n_test]\n",
    "        y_test_pct = y_test_country_pct[n_train:n_train + n_test]\n",
    "        y_test_original = y_test_country_original[n_train:n_train + n_test] if y_test_country_original is not None else None\n",
    "        \n",
    "        print(f\"Test country train samples: {len(X_train_from_test_pct)}\")\n",
    "        print(f\"Test country test samples: {len(X_test_pct)}\")\n",
    "        print(f\"Number of features: {X_train_from_test_pct.shape[1]}\")\n",
    "        \n",
    "        forecaster = SingleTargetLOCOForecaster(model_func)\n",
    "\n",
    "        # Training model with pct change normalised data\n",
    "        forecaster.train_model(X_train_pct_dict, y_train_pct_dict, train_countries)\n",
    "        \n",
    "        # Forecast\n",
    "        results = forecaster.forecast(\n",
    "            X_train_from_test_pct, y_train_from_test_pct,\n",
    "            X_test_pct, y_test_pct, test_country,\n",
    "            y_train_from_test_original, y_test_original\n",
    "        )\n",
    "        \n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba1da28",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StandardLOCOForecaster:\n",
    "    def __init__(self, model_func, input_steps=N_STEPS_IN, output_steps=N_STEPS_OUT):\n",
    "        self.model_func = model_func\n",
    "        self.input_steps = input_steps\n",
    "        self.output_steps = output_steps\n",
    "        self.model = None\n",
    "        self.X_scaler = StandardScaler()\n",
    "        self.y_scaler = StandardScaler()\n",
    "        self.is_trained = False\n",
    "        self.n_features = None\n",
    "\n",
    "    def create_sequences(self, X, y):\n",
    "        if len(X) < self.input_steps + self.output_steps:\n",
    "            return np.array([]), np.array([])\n",
    "        \n",
    "        X_seq = []\n",
    "        y_seq = []\n",
    "\n",
    "        for i in range(len(X) - self.input_steps - self.output_steps + 1):\n",
    "            X_seq.append(X[i:i + self.input_steps])\n",
    "            y_seq.append(y[i + self.input_steps:i + self.input_steps + self.output_steps])\n",
    "        \n",
    "        X_seq = np.array(X_seq)\n",
    "        y_seq = np.array(y_seq)\n",
    "\n",
    "        if len(X_seq) > 0 and len(X_seq.shape) == 2:\n",
    "            X_seq = X_seq.reshape(len(X_seq), self.input_steps, -1)\n",
    "\n",
    "        if len(y_seq) > 0 and len(y_seq.shape) == 1:\n",
    "            y_seq = y_seq.reshape(len(y_seq), self.output_steps)\n",
    "        \n",
    "        return X_seq, y_seq\n",
    "    \n",
    "    def train_model(self, X_train_pct, y_train_pct):\n",
    "        self.n_features = X_train_pct.shape[1]\n",
    "\n",
    "        # Scale the pct data\n",
    "        X_train_scaled = self.X_scaler.fit_transform(X_train_pct)\n",
    "        y_train_scaled = self.y_scaler.fit_transform(y_train_pct.reshape(-1, 1)).ravel()\n",
    "        \n",
    "        X_train_seq, y_train_seq = self.create_sequences(X_train_scaled, y_train_scaled)\n",
    "        \n",
    "        if len(X_train_seq) == 0:\n",
    "            print(f\"Not enough data to create sequences\")\n",
    "            return\n",
    "        \n",
    "        print(f\"Training sequences: {len(X_train_seq)}\")\n",
    "\n",
    "        input_shape = (self.input_steps, self.n_features)\n",
    "        self.model = self.model_func(input_shape, self.output_steps)\n",
    "\n",
    "        callbacks = [EarlyStopping(monitor='loss', patience=20, restore_best_weights=True)]\n",
    "\n",
    "        batch_size = min(16, len(X_train_seq))\n",
    "\n",
    "        self.model.fit(\n",
    "            X_train_seq, y_train_seq,\n",
    "            epochs=100,\n",
    "            batch_size=batch_size,\n",
    "            callbacks=callbacks,\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "        self.is_trained = True\n",
    "\n",
    "    def calculate_metrics(self, predictions, actuals, iteration_num):\n",
    "        if len(predictions) == 0 or len(actuals) == 0:\n",
    "            return {'iteration': iteration_num, 'rmse': np.nan, 'mase': np.nan}\n",
    "        \n",
    "        rmse_val = rmse(predictions, actuals)\n",
    "        mase_val = mase(actuals, predictions)\n",
    "        return {'iteration': iteration_num, 'rmse': rmse_val, 'mase': mase_val}\n",
    "    \n",
    "    def non_recursive_forecast(self, X_train_pct, y_train_pct, X_test_pct, y_test_pct, \n",
    "                               y_train_original=None, y_test_original=None):\n",
    "        if not self.is_trained:\n",
    "            print(\"Model not trained\")\n",
    "            return None\n",
    "        \n",
    "        # Scale pct data\n",
    "        X_train_scaled = self.X_scaler.transform(X_train_pct)\n",
    "        X_test_scaled = self.X_scaler.transform(X_test_pct)\n",
    "        \n",
    "        predictions_pct = []\n",
    "        actuals_pct = []\n",
    "        predictions_actual = []\n",
    "        actuals_actual = []\n",
    "        iterations = []\n",
    "        metrics_list = []\n",
    "\n",
    "        for iteration in range(3):\n",
    "            if iteration == 0:\n",
    "                X_window = X_train_scaled[-5:]\n",
    "                start_idx = 0\n",
    "                print(f\"    Iter {iteration}: Using last 5 train values\")\n",
    "            elif iteration == 1:\n",
    "                X_window = np.vstack([X_train_scaled[-2:], X_test_scaled[0:3]])\n",
    "                start_idx = 3\n",
    "                print(f\"    Iter {iteration}: Using last 2 train + test[0:3]\")\n",
    "            elif iteration == 2:\n",
    "                X_window = X_test_scaled[1:6]\n",
    "                start_idx = 6\n",
    "                print(f\"    Iter {iteration}: Using test[1:6]\")\n",
    "\n",
    "            X_input = X_window.reshape(1, self.input_steps, -1)\n",
    "\n",
    "            y_pred_scaled = self.model.predict(X_input, verbose=0)\n",
    "            y_pred_scaled = y_pred_scaled.flatten()\n",
    "\n",
    "            # Inverse scale to pct\n",
    "            y_pred_pct = self.y_scaler.inverse_transform(y_pred_scaled.reshape(-1, 1)).ravel()\n",
    "\n",
    "            end_idx = min(start_idx + self.output_steps, len(y_test_pct))\n",
    "            y_actual_pct = y_test_pct[start_idx:end_idx]\n",
    "\n",
    "            if y_test_original is not None and y_train_original is not None:\n",
    "                if iteration == 0:\n",
    "                    last_known_value = y_train_original[-1]\n",
    "                else:\n",
    "                    last_known_value = y_test_original[start_idx - 1]\n",
    "\n",
    "                y_pred_actual = denormalise_pct_change(y_pred_pct[:len(y_actual_pct)], last_known_value)\n",
    "                y_actual_actual = y_test_original[start_idx:end_idx]\n",
    "\n",
    "                if len(y_actual_actual) == len(y_pred_actual):\n",
    "                    predictions_actual.extend(y_pred_actual)\n",
    "                    actuals_actual.extend(y_actual_actual)\n",
    "\n",
    "                    metrics = self.calculate_metrics(y_pred_actual, y_actual_actual, iteration)\n",
    "                else:\n",
    "                    metrics = self.calculate_metrics(y_pred_pct[:len(y_actual_pct)], y_actual_pct, iteration)\n",
    "            else:\n",
    "                metrics = self.calculate_metrics(y_pred_pct[:len(y_actual_pct)], y_actual_pct, iteration)\n",
    "            \n",
    "            predictions_pct.extend(y_pred_pct[:len(y_actual_pct)])\n",
    "            actuals_pct.extend(y_actual_pct)\n",
    "            iterations.extend([iteration] * len(y_actual_pct))\n",
    "            metrics_list.append(metrics)\n",
    "            print(f\"    RMSE: {metrics['rmse']:.4f}, MASE: {metrics['mase']:.4f}\")\n",
    "        \n",
    "        results = {\n",
    "            'predictions_pct': np.array(predictions_pct),\n",
    "            'actuals_pct': np.array(actuals_pct),\n",
    "            'iterations': np.array(iterations),\n",
    "            'metrics': pd.DataFrame(metrics_list)\n",
    "        }\n",
    "\n",
    "        if len(predictions_actual) > 0:\n",
    "            results['predictions_actual'] = np.array(predictions_actual)\n",
    "            results['actuals_actual'] = np.array(actuals_actual)\n",
    "        \n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69a4539",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleCountryModel:\n",
    "    def __init__(self, features, target):\n",
    "        self.features = features\n",
    "        self.target = target\n",
    "\n",
    "    def run_single_country(self, data, country, model_func=build_lstm):\n",
    "        print(f\"\\nSingle Country Model for {country}\")\n",
    "        print(f\"Target ({self.target}) and its time lags are included\")\n",
    "\n",
    "        # Applying pct change normalisation\n",
    "        data = pct_change_features(data)\n",
    "\n",
    "        country_data = data[data['country'] == country].sort_values('year')\n",
    "\n",
    "        # Preparing features\n",
    "        country_data, feature_cols, target_col = prepare_features_target_time_lags(\n",
    "            country_data, self.features, self.target, use_lags=True\n",
    "        )\n",
    "\n",
    "        original_target_col = f'{self.target}_original'\n",
    "\n",
    "        valid_cols = feature_cols + [target_col]\n",
    "        if original_target_col in country_data.columns:\n",
    "            valid_cols.append(original_target_col)\n",
    "\n",
    "        valid_data = country_data[valid_cols].dropna()\n",
    "\n",
    "        if len(valid_cols) == 0:\n",
    "            print(f\"No valid data for {country}\")\n",
    "            return None\n",
    "        \n",
    "        n_samples = len(valid_data)\n",
    "        n_test = TEST_SAMPLES\n",
    "        n_train = n_samples - n_test\n",
    "\n",
    "        if n_train < N_STEPS_IN + N_STEPS_OUT:\n",
    "            print(f\"Not enough training data for {country}\")\n",
    "            return None\n",
    "        \n",
    "        X_pct = valid_data[feature_cols].values\n",
    "        y_pct = valid_data[target_col].values\n",
    "        y_original = valid_data[original_target_col].values if original_target_col in valid_data.columns else None\n",
    "\n",
    "        X_train_pct = X_pct[:n_train]\n",
    "        y_train_pct = y_pct[:n_train]\n",
    "        y_train_original = y_original[:n_train] if y_original is not None else None\n",
    "\n",
    "        X_test_pct = X_pct[n_train:n_train + n_test]\n",
    "        y_test_pct = y_pct[n_train:n_train + n_test]\n",
    "        y_test_original = y_original[n_train:n_train + n_test] if y_original is not None else None\n",
    "\n",
    "        print(f\"Training samples: {len(X_train_pct)}\")\n",
    "        print(f\"Test samples: {len(X_test_pct)}\")\n",
    "        print(f\"Number of features: {X_train_pct.shape[1]}\")\n",
    "\n",
    "        forecaster = StandardLOCOForecaster(model_func)\n",
    "        forecaster.train_model(X_train_pct, y_train_pct)\n",
    "        \n",
    "        results = forecaster.non_recursive_forecast(\n",
    "            X_train_pct, y_train_pct,\n",
    "            X_test_pct, y_test_pct,\n",
    "            y_train_original, y_test_original\n",
    "        )\n",
    "        \n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60d688d",
   "metadata": {},
   "source": [
    "### Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6faea67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_comparison(results, country, target, save_dir='data_export/04_plots'):\n",
    "    os.makedirs(os.path.join(save_dir, 'single_target_plots'), exist_ok=True)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(15, 5))\n",
    "    fig.suptitle(f'{country} - {target}: Single target LOCO vs Single country', fontsize=16)\n",
    "\n",
    "    model_types = ['loco', 'single']\n",
    "    model_labels = ['Single Target LOCO', 'Single Country']\n",
    "\n",
    "    for model_idx, (model_type, model_label) in enumerate(zip(model_types, model_labels)):\n",
    "        if model_type not  in results:\n",
    "            continue\n",
    "\n",
    "        model_results = results[model_type]\n",
    "\n",
    "        if 'predictions_actual' in model_results and len(model_results['predictions_actual']) > 0:\n",
    "            predictions = model_results['predictions_actual']\n",
    "            actuals = model_results['actuals_actual']\n",
    "            value_label = f'{target} (Actual Values)'\n",
    "        else:\n",
    "            predictions = model_results['predictions_pct']\n",
    "            actuals = model_results['actuals_pct']\n",
    "            value_label = f'{target} (% Change)'\n",
    "        \n",
    "        ax1 = axes[model_idx * 2]\n",
    "        ax1.plot(actuals, label='Actual', alpha=0.8, linewidth=2, color='blue')\n",
    "        ax1.plot(predictions, label='Predicted', alpha=0.8, linewidth=2, color='orange')\n",
    "        ax1.set_title(f'{model_label}')\n",
    "        ax1.set_xlabel('Time Step')\n",
    "        ax1.set_ylabel(value_label)\n",
    "        ax1.legend(loc='upper left')\n",
    "        \n",
    "        if len(predictions) >= 3:\n",
    "            ax1.axvline(x=2.5, color='gray', linestyle=':', alpha=0.3)\n",
    "        if len(predictions) >= 6:\n",
    "            ax1.axvline(x=5.5, color='gray', linestyle=':', alpha=0.3)\n",
    "        \n",
    "        residuals = predictions - actuals\n",
    "        \n",
    "        ax2 = axes[model_idx * 2 + 1]\n",
    "        colors = ['red' if r > 0 else 'blue' for r in residuals]\n",
    "        ax2.bar(range(len(residuals)), residuals, alpha=0.7, color=colors)\n",
    "        ax2.axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "        ax2.set_title(f'Residuals - {model_label}')\n",
    "        ax2.set_xlabel('Time Step')\n",
    "        ax2.set_ylabel('Prediction Error')\n",
    "        \n",
    "        if len(predictions) > 0:\n",
    "            overall_rmse = rmse(predictions, actuals)\n",
    "            overall_mase = mase(actuals, predictions)\n",
    "            \n",
    "            metrics_text = f'RMSE: {overall_rmse:.4f}\\nMASE: {overall_mase:.4f}'\n",
    "            ax1.text(0.02, 0.98, metrics_text, transform=ax1.transAxes, va='top', ha='left',\n",
    "                    bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.7),\n",
    "                    fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plot_path = os.path.join(save_dir, 'single_target_plots', f'{country}_{target}_comparison.png')\n",
    "    plt.savefig(plot_path, dpi=150, bbox_inches='tight')\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb45465e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_summary(summary_df, target, save_dir='data_export/04_plots'):\n",
    "    os.makedirs(os.path.join(save_dir, 'single_target_plots'), exist_ok=True)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    fig.suptitle(f'Single Target Comparison Summary - Target: {target}', fontsize=14)\n",
    "    \n",
    "    ax1 = axes[0]\n",
    "    \n",
    "    countries = summary_df['country'].unique()\n",
    "    x = np.arange(len(countries))\n",
    "    width = 0.35\n",
    "    \n",
    "    loco_rmse = []\n",
    "    single_rmse = []\n",
    "    \n",
    "    for country in countries:\n",
    "        loco_val = summary_df[(summary_df['country'] == country) & \n",
    "                              (summary_df['model_type'] == 'loco')]['rmse'].values\n",
    "        single_val = summary_df[(summary_df['country'] == country) & \n",
    "                                (summary_df['model_type'] == 'single')]['rmse'].values\n",
    "        \n",
    "        loco_rmse.append(loco_val[0] if len(loco_val) > 0 else 0)\n",
    "        single_rmse.append(single_val[0] if len(single_val) > 0 else 0)\n",
    "    \n",
    "    bars1 = ax1.bar(x - width/2, loco_rmse, width, label='Single Target LOCO', alpha=0.8, color='blue')\n",
    "    bars2 = ax1.bar(x + width/2, single_rmse, width, label='Single Country', alpha=0.8, color='orange')\n",
    "    \n",
    "    ax1.set_xlabel('Country')\n",
    "    ax1.set_ylabel('RMSE')\n",
    "    ax1.set_title('RMSE Comparison by Country')\n",
    "    ax1.set_xticks(x)\n",
    "    ax1.set_xticklabels(countries, rotation=45, ha='right')\n",
    "    ax1.legend(loc='upper left')\n",
    "    \n",
    "    ax2 = axes[1]\n",
    "    \n",
    "    improvement_data = []\n",
    "    \n",
    "    for country in countries:\n",
    "        loco_data = summary_df[(summary_df['country'] == country) & \n",
    "                               (summary_df['model_type'] == 'loco')]\n",
    "        single_data = summary_df[(summary_df['country'] == country) & \n",
    "                                 (summary_df['model_type'] == 'single')]\n",
    "        \n",
    "        if not loco_data.empty and not single_data.empty:\n",
    "            loco_rmse_val = loco_data['rmse'].values[0]\n",
    "            single_rmse_val = single_data['rmse'].values[0]\n",
    "            \n",
    "            improvement = ((single_rmse_val - loco_rmse_val) / single_rmse_val) * 100\n",
    "            improvement_data.append(improvement)\n",
    "        else:\n",
    "            improvement_data.append(0)\n",
    "    \n",
    "    colors_bar = ['green' if imp > 0 else 'red' for imp in improvement_data]\n",
    "    bars = ax2.bar(x, improvement_data, alpha=0.8, color=colors_bar)\n",
    "    \n",
    "    ax2.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
    "    ax2.set_xlabel('Country')\n",
    "    ax2.set_ylabel('Improvement (%)')\n",
    "    ax2.set_title('Single Target LOCO Performance vs Single Country\\n(Positive = LOCO Better)')\n",
    "    ax2.set_xticks(x)\n",
    "    ax2.set_xticklabels(countries, rotation=45, ha='right')\n",
    "    \n",
    "    for bar, value in zip(bars, improvement_data):\n",
    "        height = bar.get_height()\n",
    "        ax2.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{value:.1f}%', ha='center', va='bottom' if height > 0 else 'top',\n",
    "                fontsize=8)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plot_path = os.path.join(save_dir, 'single_target_plots', f'{target}_summary.png')\n",
    "    plt.savefig(plot_path, dpi=150, bbox_inches='tight')\n",
    "    \n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c472b893",
   "metadata": {},
   "source": [
    "### Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a245cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_single_target_comparison(countries_to_test, target='co2', model_func=build_lstm, \n",
    "                                 save_dir='data_export/04_results', \n",
    "                                 country_group='all'):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    print(f\"Target: {target}\")\n",
    "    print(f\"Model: {model_func.__name__}\")\n",
    "    print(f\"Test size: {TEST_SAMPLES} samples\")\n",
    "    print(f\"Country group: {country_group}\")\n",
    "    \n",
    "    data = load_data()\n",
    "    \n",
    "    if country_group == 'developed':\n",
    "        training_pool = DEVELOPED_COUNTRIES\n",
    "    elif country_group == 'developing':\n",
    "        training_pool = DEVELOPING_COUNTRIES\n",
    "    else:\n",
    "        training_pool = G20_COUNTRIES\n",
    "    \n",
    "    loco_comparison = SingleTargetLOCOComparison(training_pool, FEATURES, target)\n",
    "    single_country_model = SingleCountryModel(FEATURES, target)\n",
    "    \n",
    "    all_results = {}\n",
    "    comparison_summary = []\n",
    "    \n",
    "    for test_country in countries_to_test:\n",
    "        print(f\"\\nTESTING COUNTRY: {test_country}\")\n",
    "        \n",
    "        country_results = {}\n",
    "        \n",
    "        print(\"\\nSINGLE TARGET LOCO MODEL\")\n",
    "        loco_results = loco_comparison.run_comparison(data, test_country, model_func)\n",
    "        if loco_results is not None:\n",
    "            country_results['loco'] = loco_results\n",
    "        \n",
    "        print(\"\\nSINGLE COUNTRY MODEL\")\n",
    "        single_results = single_country_model.run_single_country(data, test_country, model_func)\n",
    "        if single_results is not None:\n",
    "            country_results['single'] = single_results\n",
    "        \n",
    "        all_results[test_country] = country_results\n",
    "        \n",
    "        for model_type in ['loco', 'single']:\n",
    "            if model_type in country_results:\n",
    "                res = country_results[model_type]\n",
    "                \n",
    "                if 'predictions_actual' in res and len(res['predictions_actual']) > 0:\n",
    "                    preds = res['predictions_actual']\n",
    "                    acts = res['actuals_actual']\n",
    "                    data_type = 'actual'\n",
    "                else:\n",
    "                    preds = res['predictions_pct']\n",
    "                    acts = res['actuals_pct']\n",
    "                    data_type = 'pct'\n",
    "                \n",
    "                if len(preds) > 0:\n",
    "                    comparison_summary.append({\n",
    "                        'country': test_country,\n",
    "                        'model_type': model_type,\n",
    "                        'data_type': data_type,\n",
    "                        'rmse': rmse(preds, acts),\n",
    "                        'mase': mase(acts, preds),\n",
    "                        'n_predictions': len(preds)\n",
    "                    })\n",
    "    \n",
    "    if comparison_summary:\n",
    "        summary_df = pd.DataFrame(comparison_summary)\n",
    "        \n",
    "        print(\"\\nSUMMARY\")\n",
    "        \n",
    "        for country in countries_to_test:\n",
    "            country_df = summary_df[summary_df['country'] == country]\n",
    "            if not country_df.empty:\n",
    "                print(f\"\\n{country}:\")\n",
    "                \n",
    "                loco_row = country_df[country_df['model_type'] == 'loco']\n",
    "                single_row = country_df[country_df['model_type'] == 'single']\n",
    "                \n",
    "                if not loco_row.empty and not single_row.empty:\n",
    "                    loco_rmse = loco_row.iloc[0]['rmse']\n",
    "                    single_rmse = single_row.iloc[0]['rmse']\n",
    "                    loco_mase = loco_row.iloc[0]['mase']\n",
    "                    single_mase = single_row.iloc[0]['mase']\n",
    "                    \n",
    "                    print(f\"  Single Target LOCO - RMSE: {loco_rmse:.4f}, MASE: {loco_mase:.4f}\")\n",
    "                    print(f\"  Single Country     - RMSE: {single_rmse:.4f}, MASE: {single_mase:.4f}\")\n",
    "                    \n",
    "                    if loco_rmse < single_rmse:\n",
    "                        improvement = ((single_rmse - loco_rmse) / single_rmse) * 100\n",
    "                        print(f\"    Single Target LOCO is {improvement:.1f}% better\")\n",
    "                    else:\n",
    "                        worse = ((loco_rmse - single_rmse) / single_rmse) * 100\n",
    "                        print(f\"    Single Country is {worse:.1f}% better\")\n",
    "        \n",
    "        summary_path = os.path.join(save_dir, f'{target}_{country_group}_summary.csv')\n",
    "        summary_df.to_csv(summary_path, index=False)\n",
    "        \n",
    "        for country in countries_to_test:\n",
    "            if country in all_results:\n",
    "                fig = plot_comparison(\n",
    "                    all_results[country], \n",
    "                    country, \n",
    "                    target,\n",
    "                    save_dir=save_dir\n",
    "                )\n",
    "                plt.show()\n",
    "        \n",
    "        fig_summary = plot_summary(\n",
    "            summary_df,\n",
    "            target,\n",
    "            save_dir=save_dir\n",
    "        )\n",
    "        plt.show()\n",
    "    \n",
    "    clear_memory()\n",
    "    \n",
    "    return all_results, summary_df if comparison_summary else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43e4de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_developed_comparison(countries_to_test=None, target='co2', model_func=build_lstm, save_dir='data_export/04_results'):\n",
    "    if countries_to_test is None:\n",
    "        countries_to_test = DEVELOPED_COUNTRIES\n",
    "    \n",
    "    results, summary = run_single_target_comparison(\n",
    "        countries_to_test=countries_to_test,\n",
    "        target=target,\n",
    "        model_func=model_func,\n",
    "        save_dir=save_dir,\n",
    "        country_group='developed'\n",
    "    )\n",
    "\n",
    "    if summary is not None and not summary.empty:\n",
    "        summary = summary.copy()\n",
    "        summary['strategy'] = 'non_recursive'\n",
    "    \n",
    "    return results, summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8830d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_developing_comparison(countries_to_test=None, target='co2', model_func=build_lstm, save_dir='data_export/04_results'):\n",
    "    if countries_to_test is None:\n",
    "        countries_to_test = DEVELOPING_COUNTRIES\n",
    "\n",
    "    results, summary = run_single_target_comparison(\n",
    "        countries_to_test=countries_to_test,\n",
    "        target=target,\n",
    "        model_func=model_func,\n",
    "        save_dir=save_dir,\n",
    "        country_group='developing'\n",
    "    )\n",
    "\n",
    "    if summary is not None and not summary.empty:\n",
    "        summary = summary.copy()\n",
    "        summary['strategy'] = 'non_recursive'\n",
    "    \n",
    "    return results, summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116b178f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_1target_final_summary(save_dir='data_export/04_results/1target'):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    summary_data_list = []\n",
    "\n",
    "    experiments = [\n",
    "        {\n",
    "            'target': 'co2',\n",
    "            'model_func': build_lstm,\n",
    "            'model_name': 'LSTM',\n",
    "            'country_groups': [\n",
    "                ('developed', DEVELOPED_COUNTRIES),\n",
    "                ('developing', DEVELOPING_COUNTRIES)\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'target': 'co2',\n",
    "            'model_func': build_bilstm,\n",
    "            'model_name': 'Bi-LSTM',\n",
    "            'country_groups': [\n",
    "                ('developed', DEVELOPED_COUNTRIES),\n",
    "                ('developing', DEVELOPING_COUNTRIES)\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'target': 'co2',\n",
    "            'model_func': build_edlstm,\n",
    "            'model_name': 'ED-LSTM',\n",
    "            'country_groups': [\n",
    "                ('developed', DEVELOPED_COUNTRIES),\n",
    "                ('developing', DEVELOPING_COUNTRIES)\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'target': 'co2',\n",
    "            'model_func': build_cnn,\n",
    "            'model_name': 'CNN',\n",
    "            'country_groups': [\n",
    "                ('developed', DEVELOPED_COUNTRIES),\n",
    "                ('developing', DEVELOPING_COUNTRIES)\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'target': 'gdp',\n",
    "            'model_func': build_lstm,\n",
    "            'model_name': 'LSTM',\n",
    "            'country_groups': [\n",
    "                ('developed', DEVELOPED_COUNTRIES),\n",
    "                ('developing', DEVELOPING_COUNTRIES)\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'target': 'gdp',\n",
    "            'model_func': build_bilstm,\n",
    "            'model_name': 'Bi-LSTM',\n",
    "            'country_groups': [\n",
    "                ('developed', DEVELOPED_COUNTRIES),\n",
    "                ('developing', DEVELOPING_COUNTRIES)\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'target': 'gdp',\n",
    "            'model_func': build_edlstm,\n",
    "            'model_name': 'ED-LSTM',\n",
    "            'country_groups': [\n",
    "                ('developed', DEVELOPED_COUNTRIES),\n",
    "                ('developing', DEVELOPING_COUNTRIES)\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'target': 'gdp',\n",
    "            'model_func': build_cnn,\n",
    "            'model_name': 'CNN',\n",
    "            'country_groups': [\n",
    "                ('developed', DEVELOPED_COUNTRIES),\n",
    "                ('developing', DEVELOPING_COUNTRIES)\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'target': 'primary_energy_consumption',\n",
    "            'model_func': build_lstm,\n",
    "            'model_name': 'LSTM',\n",
    "            'country_groups': [\n",
    "                ('developed', DEVELOPED_COUNTRIES),\n",
    "                ('developing', DEVELOPING_COUNTRIES)\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'target': 'primary_energy_consumption',\n",
    "            'model_func': build_bilstm,\n",
    "            'model_name': 'Bi-LSTM',\n",
    "            'country_groups': [\n",
    "                ('developed', DEVELOPED_COUNTRIES),\n",
    "                ('developing', DEVELOPING_COUNTRIES)\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'target': 'primary_energy_consumption',\n",
    "            'model_func': build_edlstm,\n",
    "            'model_name': 'ED-LSTM',\n",
    "            'country_groups': [\n",
    "                ('developed', DEVELOPED_COUNTRIES),\n",
    "                ('developing', DEVELOPING_COUNTRIES)\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'target': 'primary_energy_consumption',\n",
    "            'model_func': build_cnn,\n",
    "            'model_name': 'CNN',\n",
    "            'country_groups': [\n",
    "                ('developed', DEVELOPED_COUNTRIES),\n",
    "                ('developing', DEVELOPING_COUNTRIES)\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    for exp in experiments:\n",
    "        target = exp['target']\n",
    "        model_func = exp['model_func']\n",
    "        model_name = exp['model_name']\n",
    "        \n",
    "        for group_name, countries in exp['country_groups']:\n",
    "            print(f\"\\nRunning {target} - {model_name} - {group_name}\")\n",
    "\n",
    "            if group_name == 'developed':\n",
    "                results, summary = run_developed_comparison(\n",
    "                    countries_to_test=countries,\n",
    "                    target=target,\n",
    "                    model_func=model_func,\n",
    "                    save_dir=f'{save_dir}/{group_name}'\n",
    "                )\n",
    "            else:\n",
    "                results, summary = run_developing_comparison(\n",
    "                    countries_to_test=countries,\n",
    "                    target=target,\n",
    "                    model_func=model_func,\n",
    "                    save_dir=f'{save_dir}/{group_name}'\n",
    "                )\n",
    "\n",
    "            # Add metadata into the summary\n",
    "            if summary is not None and not summary.empty:\n",
    "                summary = summary.copy()\n",
    "                summary['target'] = target\n",
    "                summary['model'] = model_name\n",
    "                summary['country_group'] = group_name\n",
    "                summary_data_list.append(summary)\n",
    "\n",
    "            if results is not None:\n",
    "                print(f\"Plots for {target} - {model_name} - {group_name}\")\n",
    "                \n",
    "                for country in countries:\n",
    "                    if country in results:\n",
    "                        # Plot individual country comparison\n",
    "                        fig = plot_comparison(\n",
    "                            results[country], \n",
    "                            country, \n",
    "                            target=target,\n",
    "                            save_dir=f'{save_dir}/{group_name}'\n",
    "                        )\n",
    "                        plt.close(fig)\n",
    "                \n",
    "                # Summary plot for this experiment\n",
    "                if summary is not None and not summary.empty:\n",
    "                    fig_summary = plot_summary(\n",
    "                        summary,\n",
    "                        target=target,\n",
    "                        save_dir=f'{save_dir}/{group_name}'\n",
    "                    )\n",
    "                    plt.close(fig_summary)\n",
    "            \n",
    "            clear_memory()\n",
    "    \n",
    "    # Combine all summaries\n",
    "    if not summary_data_list:\n",
    "        print(\"No summary data collected\")\n",
    "        return None\n",
    "    \n",
    "    combined_summary = pd.concat(summary_data_list, ignore_index=True)\n",
    "    \n",
    "    # Create final summary table\n",
    "    final_summary_rows = []\n",
    "    \n",
    "    # Group by all relevant dimensions\n",
    "    grouping_cols = ['target', 'model', 'country_group', 'strategy', 'model_type']\n",
    "    \n",
    "    for group_key, group_data in combined_summary.groupby(grouping_cols):\n",
    "        target, model, country_group, strategy, model_type = group_key\n",
    "        \n",
    "        # Map model_type to the names\n",
    "        data_type = \"Single Country\" if model_type == 'single' else \"All Country (LOCO)\"\n",
    "        \n",
    "        # Calculate aggregated metrics\n",
    "        rmse_values = group_data['rmse'].dropna()\n",
    "        mase_values = group_data['mase'].dropna()\n",
    "        \n",
    "        if len(rmse_values) > 0:\n",
    "            # Summary stats\n",
    "            max_rmse_idx = group_data['rmse'].idxmax()\n",
    "            min_rmse_idx = group_data['rmse'].idxmin()\n",
    "            max_rmse_country = group_data.loc[max_rmse_idx, 'country']\n",
    "            min_rmse_country = group_data.loc[min_rmse_idx, 'country']\n",
    "            \n",
    "            final_summary_rows.append({\n",
    "                'Data_Type': data_type,\n",
    "                'Method': 'Autoregressive - 4 lags',\n",
    "                'Strategy': strategy.replace('_', '-').title(),\n",
    "                'Model': model,\n",
    "                'Target': target.replace('_', ' ').title(),\n",
    "                'Country_Group': country_group.title(),\n",
    "                'Avg_RMSE': rmse_values.mean(),\n",
    "                'Median_RMSE': rmse_values.median(),\n",
    "                'Max_RMSE': rmse_values.max(),\n",
    "                'Min_RMSE': rmse_values.min(),\n",
    "                'Max_RMSE_Country': max_rmse_country,\n",
    "                'Min_RMSE_Country': min_rmse_country,\n",
    "                'Avg_MASE': mase_values.mean() if len(mase_values) > 0 else np.nan,\n",
    "                'N_Countries': len(group_data)\n",
    "            })\n",
    "    \n",
    "    # Create DataFrame\n",
    "    final_summary_df = pd.DataFrame(final_summary_rows)\n",
    "    \n",
    "    # Sort by target, country group, model type\n",
    "    final_summary_df = final_summary_df.sort_values([\n",
    "        'Target', 'Country_Group', 'Model', 'Strategy', 'Data_Type'\n",
    "    ]).reset_index(drop=True)\n",
    "    \n",
    "    # Save to CSV\n",
    "    summary_path = os.path.join(save_dir, '1target_summary_table.csv')\n",
    "    final_summary_df.to_csv(summary_path, index=False, float_format='%.4f')\n",
    "    \n",
    "    return final_summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65dcc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_performance_comparison_table(final_summary_df, save_dir='data_export/04_results/1target'):\n",
    "    if final_summary_df is None:\n",
    "        print(\"No summary data available for comparison\")\n",
    "        return None\n",
    "    \n",
    "    comparison_rows = []\n",
    "    \n",
    "    # Group by target, model, country_group, strategy to compare LOCO vs Single\n",
    "    grouping_cols = ['Target', 'Model', 'Country_Group', 'Strategy']\n",
    "    \n",
    "    for group_key, group_data in final_summary_df.groupby(grouping_cols):\n",
    "        target, model, country_group, strategy = group_key\n",
    "        \n",
    "        # LOCO and Single Country results\n",
    "        loco_data = group_data[group_data['Data_Type'] == 'All Country (LOCO)']\n",
    "        single_data = group_data[group_data['Data_Type'] == 'Single Country']\n",
    "        \n",
    "        if not loco_data.empty and not single_data.empty:\n",
    "            loco_rmse = loco_data['Avg_RMSE'].iloc[0]\n",
    "            single_rmse = single_data['Avg_RMSE'].iloc[0]\n",
    "            \n",
    "            # Calculate improvement percentage\n",
    "            if single_rmse != 0:\n",
    "                improvement_pct = ((single_rmse - loco_rmse) / single_rmse) * 100\n",
    "            else:\n",
    "                improvement_pct = 0\n",
    "            \n",
    "            better_method = \"LOCO\" if loco_rmse < single_rmse else \"Single Country\"\n",
    "            \n",
    "            comparison_rows.append({\n",
    "                'Target': target,\n",
    "                'Model': model,\n",
    "                'Country_Group': country_group,\n",
    "                'Strategy': strategy,\n",
    "                'LOCO_Avg_RMSE': loco_rmse,\n",
    "                'Single_Avg_RMSE': single_rmse,\n",
    "                'Better_Method': better_method,\n",
    "                'Improvement_Pct': abs(improvement_pct)\n",
    "            })\n",
    "    \n",
    "    comparison_df = pd.DataFrame(comparison_rows)\n",
    "    \n",
    "    if not comparison_df.empty:\n",
    "        # Save comparison table\n",
    "        comparison_path = os.path.join(save_dir, '1target_performance_comparison_table.csv')\n",
    "        comparison_df.to_csv(comparison_path, index=False, float_format='%.4f')\n",
    "        \n",
    "        better_counts = comparison_df['Better_Method'].value_counts()\n",
    "        total_comparisons = len(comparison_df)\n",
    "        \n",
    "        for method, count in better_counts.items():\n",
    "            pct = (count / total_comparisons) * 100\n",
    "            print(f\"{method}: {count}/{total_comparisons} ({pct:.1f}%)\")\n",
    "        \n",
    "        # Show average improvement by method\n",
    "        loco_wins = comparison_df[comparison_df['Better_Method'] == 'LOCO']\n",
    "        single_wins = comparison_df[comparison_df['Better_Method'] == 'Single Country']\n",
    "        \n",
    "        if not loco_wins.empty:\n",
    "            avg_loco_improvement = loco_wins['Improvement_Pct'].mean()\n",
    "            print(f\"\\nAverage improvement when LOCO wins: {avg_loco_improvement:.2f}%\")\n",
    "        \n",
    "        if not single_wins.empty:\n",
    "            avg_single_improvement = single_wins['Improvement_Pct'].mean()\n",
    "            print(f\"Average improvement when Single Country wins: {avg_single_improvement:.2f}%\")\n",
    "    \n",
    "    return comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1fddc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_summary = create_1target_final_summary()\n",
    "performance_comparison = generate_performance_comparison_table(final_summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
