{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6fac95f",
   "metadata": {},
   "source": [
    "# Leave One Country Out vs Single country\n",
    "## This shows the rmse breakdowns so which can be compared and seen easier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156414be",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f21ddd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import gc\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Bidirectional, Input\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, RepeatVector, TimeDistributed\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad814fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Configuration\n",
    "TARGET_VARIABLES = ['co2', 'gdp', 'primary_energy_consumption']\n",
    "N_STEPS_IN = 5\n",
    "N_STEPS_OUT = 3\n",
    "# Setting test size as 9 samples\n",
    "TEST_SAMPLES = 9\n",
    "MAX_LAGS = 4\n",
    "\n",
    "G20_COUNTRIES = [\n",
    "    'United States', 'China', 'Japan', 'Germany', \n",
    "    'United Kingdom', 'France', 'Italy', 'Canada',\n",
    "    'Brazil', 'Russia', 'India', 'Australia', \n",
    "    'Mexico', 'Indonesia', 'Turkey', 'Saudi Arabia',\n",
    "    'South Africa', 'Argentina', 'South Korea'\n",
    "]\n",
    "\n",
    "FEATURES = [\n",
    "    'fossil_fuel_consumption', 'energy_per_capita',\n",
    "    'electricity_generation', 'population',\n",
    "    'nuclear_consumption', 'renewables_consumption'\n",
    "]\n",
    "\n",
    "DEVELOPED_COUNTRIES = [\n",
    "    'United States', 'Japan', 'Germany', 'United Kingdom',\n",
    "    'France', 'Italy', 'Canada', 'Australia', 'South Korea'\n",
    "]\n",
    "\n",
    "DEVELOPING_COUNTRIES = [\n",
    "    'China', 'Brazil', 'Russia', 'India', 'Mexico', 'Indonesia',\n",
    "    'Turkey', 'Saudi Arabia', 'South Africa', 'Argentina'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b707cc",
   "metadata": {},
   "source": [
    "### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341cf27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_memory():\n",
    "    tf.keras.backend.clear_session()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a087c1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_pred, y_actual):\n",
    "    y_pred = np.atleast_1d(y_pred)\n",
    "    y_actual = np.atleast_1d(y_actual)\n",
    "    \n",
    "    if len(y_pred) == 1 and len(y_actual) == 1:\n",
    "        # Single value case\n",
    "        return np.sqrt((y_pred[0] - y_actual[0]) ** 2)\n",
    "    else:\n",
    "        # Array case\n",
    "        return np.sqrt(mean_squared_error(y_actual, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4b9cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mase(y_actual, y_pred, period=1):\n",
    "    y_pred = np.atleast_1d(y_pred)\n",
    "    y_actual = np.atleast_1d(y_actual)\n",
    "    \n",
    "    if len(y_pred) == 1 and len(y_actual) == 1:\n",
    "        # For single values, return absolute error\n",
    "        return np.abs(y_pred[0] - y_actual[0])\n",
    "\n",
    "    mae_forecast = mean_absolute_error(y_actual, y_pred)\n",
    "    \n",
    "    # MAE of naive forecast\n",
    "    naive_forecast = y_actual[:-period] if period > 0 else y_actual[:-1]\n",
    "    actual_for_naive = y_actual[period:] if period > 0 else y_actual[1:]\n",
    "    \n",
    "    if len(naive_forecast) == 0:\n",
    "        return np.nan\n",
    "    \n",
    "    mae_naive = mean_absolute_error(actual_for_naive, naive_forecast)\n",
    "    \n",
    "    if mae_naive == 0:\n",
    "        return 0 if mae_forecast == 0 else np.inf\n",
    "    \n",
    "    return mae_forecast / mae_naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57db226a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pct_change_features(data):\n",
    "    \"\"\"\n",
    "    This is to convert the series into the percentage change from the previous time step\n",
    "    -> It will lead the data more stationary\n",
    "    Avoiding NaN in the first row\n",
    "    \"\"\"\n",
    "    data = data.copy()\n",
    "\n",
    "    # For each feature, calculate pct_change with lag1\n",
    "    for feature in FEATURES + TARGET_VARIABLES:\n",
    "        if feature in data.columns:\n",
    "            # Store original values\n",
    "            data[f'{feature}_original'] = data[feature].values.copy()\n",
    "            \n",
    "            # pct_change\n",
    "            if f'{feature}_lag1' in data.columns:\n",
    "                lag1_values = data[f'{feature}_lag1'].values\n",
    "                current_values = data[feature].values\n",
    "\n",
    "                # Create mask for non-zero lag values\n",
    "                non_zero_mask = lag1_values != 0\n",
    "                pct_change = np.zeros_like(current_values)\n",
    "            \n",
    "                # Calculate pct change only where lag1 is non-zero (curr - lag1) / lag1\n",
    "                pct_change[non_zero_mask] = (current_values[non_zero_mask] - lag1_values[non_zero_mask]) / lag1_values[non_zero_mask]\n",
    "                \n",
    "                data[f'{feature}_pct'] = pct_change\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea6d816",
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalise_pct_change(pct_preds, last_actual_value):\n",
    "    \"\"\"\n",
    "    Conver pct_change preds back to the original scale\n",
    "    value_t = value_{t-1} * (1 + pct_change_t)\n",
    "    \"\"\"\n",
    "    actual_values = []\n",
    "    curr_val = last_actual_value\n",
    "    \n",
    "    for pct in pct_preds:\n",
    "        next_value = curr_val * (1 + pct)\n",
    "        actual_values.append(next_value)\n",
    "        curr_val = next_value\n",
    "    \n",
    "    return np.array(actual_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553b6de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features_with_target_lags(data, features, current_target, use_lags=True):\n",
    "    \"\"\"\n",
    "    Preparing feature matrix with time lag features and the designated target (including target as a feature)\n",
    "    This is to let the model see the target's historical values\n",
    "    \"\"\"\n",
    "    feature_cols = []\n",
    "\n",
    "    all_features_and_targets = features.copy()\n",
    "    for target in TARGET_VARIABLES:\n",
    "        if target not in all_features_and_targets:\n",
    "            all_features_and_targets.append(target)\n",
    "\n",
    "    for feature in all_features_and_targets:\n",
    "        if f'{feature}_pct' in data.columns:\n",
    "            feature_cols.append(f'{feature}_pct')\n",
    "        elif feature in data.columns:\n",
    "            print(f\"{feature}_pct not included, using raw values\")\n",
    "            feature_cols.append(feature)\n",
    "        \n",
    "        if use_lags:\n",
    "            for lag in range(1, MAX_LAGS+1):\n",
    "                lag_col = f'{feature}_lag{lag}'\n",
    "\n",
    "                if lag_col in data.columns:\n",
    "                    if lag < MAX_LAGS:\n",
    "                        next_lag = f'{feature}_lag{lag+1}'\n",
    "                        if next_lag in data.columns:\n",
    "                            lag_values = data[lag_col].values\n",
    "                            next_lag_values = data[next_lag].values\n",
    "\n",
    "                            non_zero_mask = next_lag_values != 0\n",
    "                            pct_lag = np.zeros_like(lag_values)\n",
    "                            pct_lag[non_zero_mask] = (lag_values[non_zero_mask] - next_lag_values[non_zero_mask]) / next_lag_values[non_zero_mask]\n",
    "                            \n",
    "                            pct_lag_col = f'{feature}_lag{lag}_pct'\n",
    "                            data[pct_lag_col] = pct_lag\n",
    "                            feature_cols.append(pct_lag_col)\n",
    "                    else:\n",
    "                        pct_lag_col = f'{feature}_lag{lag}_pct'\n",
    "                        if pct_lag_col in data.columns:\n",
    "                            feature_cols.append(pct_lag_col)\n",
    "\n",
    "    if f'{current_target}_pct' in data.columns:\n",
    "        target_col = f'{current_target}_pct'\n",
    "    else:\n",
    "        print(f\"{current_target}_pct not included, using raw target values\")\n",
    "        target_col = target\n",
    "\n",
    "    # Removing duplicates and preserve the order\n",
    "    shown = set()\n",
    "    feature_cols_unique = []\n",
    "    for col in feature_cols:\n",
    "        if col not in shown:\n",
    "            shown.add(col)\n",
    "            feature_cols_unique.append(col)\n",
    "    \n",
    "    return data, feature_cols_unique, target_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0309269",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features(data, features, target, use_lags=True):\n",
    "    \"\"\"\n",
    "    Preparing feature matrix with lag features and pct changes\n",
    "    \"\"\"\n",
    "    feature_cols = []\n",
    "\n",
    "    all_features = features.copy()\n",
    "    if target not in all_features:\n",
    "        all_features.append(target)\n",
    "\n",
    "    for feature in all_features:\n",
    "        # Use the original column\n",
    "        if feature in data.columns:\n",
    "            feature_cols.append(feature)\n",
    "        # Or use the _pct column if it exists\n",
    "        elif f'{feature}_pct' in data.columns:\n",
    "            feature_cols.append(f'{feature}_pct')\n",
    "\n",
    "        # Lag features\n",
    "        if use_lags:\n",
    "            for lag in range(1, 5):\n",
    "                lag_col = f'{feature}_lag{lag}'\n",
    "\n",
    "                if lag_col in data.columns:\n",
    "                    # Calculate pct change for lag features\n",
    "                    if lag < 4:\n",
    "                        next_lag = f'{feature}_lag{lag+1}'\n",
    "                        if next_lag in data.columns:\n",
    "                            lag_values = data[lag_col].values\n",
    "                            next_lag_values = data[next_lag].values\n",
    "                            \n",
    "                            non_zero_mask = next_lag_values != 0\n",
    "                            pct_lag = np.zeros_like(lag_values)\n",
    "                            pct_lag[non_zero_mask] = (lag_values[non_zero_mask] - next_lag_values[non_zero_mask]) / next_lag_values[non_zero_mask]\n",
    "                            \n",
    "                            pct_lag_col = f'{feature}_lag{lag}_pct'\n",
    "                            data[pct_lag_col] = pct_lag\n",
    "                            feature_cols.append(pct_lag_col)\n",
    "    \n",
    "    if f'{target}_pct' in data.columns:\n",
    "        target_col = f'{target}_pct'\n",
    "    else:\n",
    "        target_col = target\n",
    "    \n",
    "    return data, feature_cols, target_col"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb45b49",
   "metadata": {},
   "source": [
    "### Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75b9a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(save_dir='data_export'):\n",
    "    lag_path = os.path.join(save_dir, 'lag_df_1965.pkl')\n",
    "    lag_df = pd.read_pickle(lag_path)\n",
    "    print(f\"Data Shape: {lag_df.shape}\")\n",
    "    return lag_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7829ecd4",
   "metadata": {},
   "source": [
    "### Model builds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e700e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm(input_shape, output_shape, hidden=32):\n",
    "    model = Sequential([\n",
    "        LSTM(hidden, activation='relu', input_shape=input_shape, kernel_regularizer=l2(0.01)),\n",
    "        Dense(output_shape)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.01), loss='mse', metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c98f964",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_bilstm(input_shape, output_shape, hidden=16):\n",
    "    model = Sequential([\n",
    "        Bidirectional(LSTM(hidden, activation='relu', kernel_regularizer=l2(0.001), recurrent_regularizer=l2(0.01)),\n",
    "                      input_shape=input_shape),\n",
    "        Dense(output_shape)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.01), loss='mse', metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f402484b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_edlstm(input_shape, output_shape, hidden=16):\n",
    "    model = Sequential([\n",
    "        LSTM(hidden, activation='relu', input_shape=input_shape, kernel_regularizer=l2(0.01)),\n",
    "        RepeatVector(output_shape),\n",
    "        LSTM(hidden, activation='relu', return_sequences=True, kernel_regularizer=l2(0.01)),\n",
    "        TimeDistributed(Dense(1))\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.01), loss='mse', metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30b625c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn(input_shape, output_shape, filters=32, hidden=16):\n",
    "    model = Sequential([\n",
    "        Conv1D(filters=filters, kernel_size=3, activation='relu', input_shape=input_shape, padding='same', kernel_regularizer=l2(0.01)),\n",
    "        Flatten(),\n",
    "        Dense(hidden, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        Dense(output_shape)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.01), loss='mse', metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4d129c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_multioutput_model(input_shape, n_features, output_steps, hidden=16):\n",
    "    \"\"\"\n",
    "    This model predicts both Y and X features\n",
    "    \"\"\"\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    # LSTM process\n",
    "    lstm_out = LSTM(hidden, activation='relu', return_sequences=False)(inputs)\n",
    "\n",
    "    # Output for target\n",
    "    y_output = Dense(output_steps, name='y_output')(lstm_out)\n",
    "\n",
    "    # Output for features\n",
    "    x_output_flat = Dense(output_steps * n_features, name='x_output')(lstm_out)\n",
    "    x_output = tf.keras.layers.Reshape((output_steps, n_features), name='x_reshape')(x_output_flat)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=[y_output, x_output])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.01),\n",
    "        loss={'y_output': 'mse', 'x_output': 'mse'},\n",
    "        loss_weights={'y_output': 1.0, 'x_output': 0.5}, # More weights for y_output\n",
    "        metrics={'y_output': 'mae', 'x_output': 'mae'}\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8df68f",
   "metadata": {},
   "source": [
    "### LOCO with All target\n",
    "Leave One Country Out with the all targets and their lags but also with breakdowns of metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b70944f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LOCOForecaster:\n",
    "    def __init__(self, model_func, input_steps=N_STEPS_IN, output_steps=N_STEPS_OUT):\n",
    "        self.model_func = model_func\n",
    "        self.input_steps = input_steps\n",
    "        self.output_steps = output_steps\n",
    "        self.model = None\n",
    "        self.country_scalers = {}\n",
    "        self.is_trained = False\n",
    "        self.n_features = None\n",
    "\n",
    "    def create_sequences(self, X, y):\n",
    "        if len(X) < self.input_steps + self.output_steps:\n",
    "            return np.array([]), np.array([])\n",
    "        \n",
    "        X_seq = []\n",
    "        y_seq = []\n",
    "\n",
    "        for i in range(len(X) - self.input_steps - self.output_steps + 1):\n",
    "            X_seq.append(X[i:i + self.input_steps])\n",
    "            y_seq.append(y[i + self.input_steps:i + self.input_steps + self.output_steps])\n",
    "        \n",
    "        X_seq = np.array(X_seq)\n",
    "        y_seq = np.array(y_seq)\n",
    "\n",
    "        if len(X_seq) > 0 and len(X_seq.shape) == 2:\n",
    "            X_seq = X_seq.reshape(len(X_seq), self.input_steps, -1)\n",
    "\n",
    "        if len(y_seq) > 0 and len(y_seq.shape) == 1:\n",
    "            y_seq = y_seq.reshape(len(y_seq), self.output_steps)\n",
    "        \n",
    "        return X_seq, y_seq\n",
    "    \n",
    "    def train_model(self, X_train_pct_dict, y_train_pct_dict, countries_train):\n",
    "        \"\"\"\"\n",
    "        Training with country-specific normalisation\n",
    "        \"\"\"\n",
    "        X_train_scaled_list = []\n",
    "        y_train_scaled_list = []\n",
    "        \n",
    "        for country in countries_train:\n",
    "            if country not in X_train_pct_dict or country not in y_train_pct_dict:\n",
    "                continue\n",
    "                \n",
    "            X_country_pct = X_train_pct_dict[country]\n",
    "            y_country_pct = y_train_pct_dict[country]\n",
    "            \n",
    "            if len(X_country_pct) == 0:\n",
    "                continue\n",
    "\n",
    "            # Country-specific scalers\n",
    "            scaler_X = StandardScaler()\n",
    "            scaler_y = StandardScaler()\n",
    "            \n",
    "            X_scaled = scaler_X.fit_transform(X_country_pct)\n",
    "            y_scaled = scaler_y.fit_transform(y_country_pct.reshape(-1, 1)).ravel()\n",
    "            \n",
    "            self.country_scalers[country] = {\n",
    "                'X_scaler': scaler_X,\n",
    "                'y_scaler': scaler_y\n",
    "            }\n",
    "            \n",
    "            X_train_scaled_list.append(X_scaled)\n",
    "            y_train_scaled_list.append(y_scaled)\n",
    "        \n",
    "        X_train_combined = np.vstack(X_train_scaled_list)\n",
    "        y_train_combined = np.hstack(y_train_scaled_list)\n",
    "        \n",
    "        self.n_features = X_train_combined.shape[1]\n",
    "        \n",
    "        X_train_seq, y_train_seq = self.create_sequences(X_train_combined, y_train_combined)\n",
    "        \n",
    "        if len(X_train_seq) == 0:\n",
    "            print(\"Not enough data to create sequences\")\n",
    "            return\n",
    "        \n",
    "        print(f\"Training seq: {len(X_train_seq)}\")\n",
    "        print(f\"Feature dim: {self.n_features}\")\n",
    "\n",
    "        input_shape = (self.input_steps, self.n_features)\n",
    "        self.model = self.model_func(input_shape, self.output_steps)\n",
    "\n",
    "        callbacks = [EarlyStopping(monitor='loss', patience=20, restore_best_weights=True)]\n",
    "\n",
    "        batch_size = min(16, len(X_train_seq))\n",
    "        \n",
    "        self.model.fit(\n",
    "            X_train_seq, y_train_seq,\n",
    "            epochs=100,\n",
    "            batch_size=batch_size,\n",
    "            callbacks=callbacks,\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "        self.is_trained = True\n",
    "\n",
    "    def calculate_stepwise_metrics(self, pred_pct, actual_pct, pred_actual, actual_actual, iteration_num, start_idx):\n",
    "        metrics_list = []\n",
    "\n",
    "        # Ensure all inputs are 1D arrays\n",
    "        pred_pct = np.array(pred_pct).flatten()\n",
    "        actual_pct = np.array(actual_pct).flatten()\n",
    "        \n",
    "        min_length = min(len(pred_pct), len(actual_pct))\n",
    "        pred_pct = pred_pct[:min_length]\n",
    "        actual_pct = actual_pct[:min_length]\n",
    "        \n",
    "        if pred_actual is not None and actual_actual is not None:\n",
    "            pred_actual = np.array(pred_actual).flatten()[:min_length]\n",
    "            actual_actual = np.array(actual_actual).flatten()[:min_length]\n",
    "\n",
    "        for step in range(min_length):\n",
    "            stepwise_metrics = {\n",
    "                'iteration': iteration_num,\n",
    "                'step': step + 1,\n",
    "                'global_position': start_idx + step\n",
    "            }\n",
    "            \n",
    "            # Ensuring single values\n",
    "            pred_val = pred_pct[step]\n",
    "            actual_val = actual_pct[step]\n",
    "\n",
    "            # pct_change metrics\n",
    "            stepwise_metrics['rmse_pct'] = rmse(pred_val, actual_val)\n",
    "            stepwise_metrics['mase_pct'] = mase(actual_val, pred_val)\n",
    "\n",
    "            # actual values metrics\n",
    "            if pred_actual is not None and actual_actual is not None:\n",
    "                if step < len(pred_actual) and step < len(actual_actual):\n",
    "                    pred_actual_val = pred_actual[step]\n",
    "                    actual_actual_val = actual_actual[step]\n",
    "                    \n",
    "                    stepwise_metrics['rmse_actual'] = rmse(pred_actual_val, actual_actual_val)\n",
    "                    stepwise_metrics['mase_actual'] = mase(actual_actual_val, pred_actual_val)\n",
    "                else:\n",
    "                    stepwise_metrics['rmse_actual'] = np.nan\n",
    "                    stepwise_metrics['mase_actual'] = np.nan\n",
    "            else:\n",
    "                stepwise_metrics['rmse_actual'] = np.nan\n",
    "                stepwise_metrics['mase_actual'] = np.nan\n",
    "            \n",
    "            metrics_list.append(stepwise_metrics)\n",
    "\n",
    "        return metrics_list\n",
    "    \n",
    "    def forecast(self, X_train_pct, y_train_pct, X_test_pct, y_test_pct, target_country, y_train_original=None, y_test_original=None):\n",
    "        if not self.is_trained:\n",
    "            print(\"Model not trained\")\n",
    "            return None\n",
    "        \n",
    "        if target_country in self.country_scalers:\n",
    "            scaler_X = self.country_scalers[target_country]['X_scaler']\n",
    "            scaler_y = self.country_scalers[target_country]['y_scaler']\n",
    "        else:\n",
    "            scaler_X = StandardScaler()\n",
    "            scaler_y = StandardScaler()\n",
    "            scaler_X.fit(X_train_pct)\n",
    "            scaler_y.fit(y_train_pct.reshape(-1, 1))\n",
    "            self.country_scalers[target_country] = {\n",
    "                'X_scaler': scaler_X,\n",
    "                'y_scaler': scaler_y\n",
    "            }\n",
    "        \n",
    "        X_train_scaled = scaler_X.transform(X_train_pct)\n",
    "        X_test_scaled = scaler_X.transform(X_test_pct)\n",
    "        \n",
    "        predictions_pct = []\n",
    "        actuals_pct = []\n",
    "        predictions_actual = []\n",
    "        actuals_actual = []\n",
    "        iterations = []\n",
    "        stepwise_metrics = []\n",
    "\n",
    "        for iteration in range(3):\n",
    "            if iteration == 0:\n",
    "                X_window = X_train_scaled[-5:]\n",
    "                start_idx = 0\n",
    "                print(f\"    Iter {iteration}: Using last 5 train values\")\n",
    "            elif iteration == 1:\n",
    "                X_window = np.vstack([X_train_scaled[-2:], X_test_scaled[0:3]])\n",
    "                start_idx = 3\n",
    "                print(f\"    Iter {iteration}: Using last 2 train + test[0:3]\")\n",
    "            elif iteration == 2:\n",
    "                X_window = X_test_scaled[1:6]\n",
    "                start_idx = 6\n",
    "                print(f\"    Iter {iteration}: Using test[1:6]\")\n",
    "\n",
    "            X_input = X_window.reshape(1, self.input_steps, -1)\n",
    "\n",
    "            y_pred_scaled = self.model.predict(X_input, verbose=0)\n",
    "            y_pred_scaled = y_pred_scaled.flatten()\n",
    "\n",
    "            # Inverse scale back to pct_change\n",
    "            y_pred_pct = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).ravel()\n",
    "\n",
    "            end_idx = min(start_idx + self.output_steps, len(y_test_pct))\n",
    "            y_actual_pct = y_test_pct[start_idx:end_idx]\n",
    "\n",
    "            # Convert back to original values\n",
    "            y_pred_actual = None\n",
    "            y_actual_actual = None\n",
    "\n",
    "            if y_test_original is not None and y_train_original is not None:\n",
    "                if iteration == 0:\n",
    "                    last_known_value = y_train_original[-1]\n",
    "                else:\n",
    "                    last_known_value = y_test_original[start_idx - 1]\n",
    "\n",
    "                y_pred_actual = denormalise_pct_change(y_pred_pct[:len(y_actual_pct)], last_known_value)\n",
    "                y_actual_actual = y_test_original[start_idx:end_idx]\n",
    "\n",
    "                if len(y_actual_actual) == len(y_pred_actual):\n",
    "                    predictions_actual.extend(y_pred_actual)\n",
    "                    actuals_actual.extend(y_actual_actual)\n",
    "\n",
    "            step_metrics = self.calculate_stepwise_metrics(y_pred_pct[:len(y_actual_pct)], y_actual_pct,\n",
    "                                                           y_pred_actual, y_actual_actual, iteration, start_idx)\n",
    "            stepwise_metrics.extend(step_metrics)\n",
    "            \n",
    "            predictions_pct.extend(y_pred_pct[:len(y_actual_pct)])\n",
    "            actuals_pct.extend(y_actual_pct)\n",
    "            iterations.extend([iteration] * len(y_actual_pct))\n",
    "\n",
    "            for sm in step_metrics:\n",
    "                print(f\"    Step {sm['step']}: RMSE_pct={sm['rmse_pct']:.4f}, RMSE_actual={sm['rmse_actual']:.4f}\")\n",
    "\n",
    "        results = {\n",
    "            'predictions_pct': np.array(predictions_pct),\n",
    "            'actuals_pct': np.array(actuals_pct),\n",
    "            'predictions_actual': np.array(predictions_actual) if predictions_actual else None,\n",
    "            'actuals_actual': np.array(actuals_actual) if actuals_actual else None,\n",
    "            'iterations': np.array(iterations),\n",
    "            'stepwise_metrics': pd.DataFrame(stepwise_metrics)\n",
    "        }\n",
    "        \n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea6d4ac",
   "metadata": {},
   "source": [
    "### All Target LOCO Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a3e136",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LOCOComparison:\n",
    "    def __init__(self, countries, features, target):\n",
    "        self.countries = countries\n",
    "        self.features = features\n",
    "        self.target = target\n",
    "\n",
    "    def run_comparison(self, data, test_country, model_func=build_lstm):\n",
    "        print(f\"All Targets LOCO for: {test_country}\")\n",
    "        print(f\"Predicting: {self.target} + its lags\")\n",
    "\n",
    "        # Applying pct change normalisation to all data\n",
    "        data = pct_change_features(data)\n",
    "        \n",
    "        train_countries = [c for c in self.countries if c != test_country]\n",
    "        \n",
    "        X_train_pct_dict = {}\n",
    "        y_train_pct_dict = {}\n",
    "        \n",
    "        for country in train_countries:\n",
    "            country_data = data[data['country'] == country].sort_values('year')\n",
    "            \n",
    "            # Use all targets as features (in pct)\n",
    "            country_data, feature_cols, target_col = prepare_features_with_target_lags(\n",
    "                country_data, self.features, self.target, use_lags=True\n",
    "            )\n",
    "            \n",
    "            original_target_col = f'{self.target}_original'\n",
    "            \n",
    "            valid_cols = feature_cols + [target_col]\n",
    "            if original_target_col in country_data.columns:\n",
    "                valid_cols.append(original_target_col)\n",
    "            \n",
    "            valid_data = country_data[valid_cols].dropna()\n",
    "            \n",
    "            if len(valid_data) > 0:\n",
    "                X_pct = valid_data[feature_cols].values\n",
    "                y_pct = valid_data[target_col].values\n",
    "                \n",
    "                X_train_pct_dict[country] = X_pct\n",
    "                y_train_pct_dict[country] = y_pct\n",
    "        \n",
    "        if len(X_train_pct_dict) == 0:\n",
    "            print(\"No training data available\")\n",
    "            return None\n",
    "        \n",
    "        print(f\"Training data from {len(X_train_pct_dict)} countries\")\n",
    "\n",
    "        # Test country data\n",
    "        test_data = data[data['country'] == test_country].sort_values('year')\n",
    "        test_data, feature_cols, target_col = prepare_features_with_target_lags(\n",
    "            test_data, self.features, self.target, use_lags=True\n",
    "        )\n",
    "        \n",
    "        original_target_col = f'{self.target}_original'\n",
    "        test_valid_cols = feature_cols + [target_col]\n",
    "        if original_target_col in test_data.columns:\n",
    "            test_valid_cols.append(original_target_col)\n",
    "        \n",
    "        test_valid = test_data[test_valid_cols].dropna()\n",
    "        \n",
    "        if len(test_valid) == 0:\n",
    "            print(f\"No valid data for {test_country}\")\n",
    "            return None\n",
    "        \n",
    "        n_test_country_samples = len(test_valid)\n",
    "        n_test = TEST_SAMPLES\n",
    "        n_train = n_test_country_samples - n_test\n",
    "        \n",
    "        if n_train < N_STEPS_IN:\n",
    "            print(f\"Not enough training data for {test_country}\")\n",
    "            return None\n",
    "        \n",
    "        X_test_country_pct = test_valid[feature_cols].values\n",
    "        y_test_country_pct = test_valid[target_col].values\n",
    "        y_test_country_original = test_valid[original_target_col].values if original_target_col in test_valid.columns else None\n",
    "        \n",
    "        X_train_from_test_pct = X_test_country_pct[:n_train]\n",
    "        y_train_from_test_pct = y_test_country_pct[:n_train]\n",
    "        y_train_from_test_original = y_test_country_original[:n_train] if y_test_country_original is not None else None\n",
    "        \n",
    "        X_test_pct = X_test_country_pct[n_train:n_train + n_test]\n",
    "        y_test_pct = y_test_country_pct[n_train:n_train + n_test]\n",
    "        y_test_original = y_test_country_original[n_train:n_train + n_test] if y_test_country_original is not None else None\n",
    "        \n",
    "        print(f\"Test country train samples: {len(X_train_from_test_pct)}\")\n",
    "        print(f\"Test country test samples: {len(X_test_pct)}\")\n",
    "        \n",
    "        forecaster = LOCOForecaster(model_func)\n",
    "\n",
    "        # Training model with pct change normalised data\n",
    "        forecaster.train_model(X_train_pct_dict, y_train_pct_dict, train_countries)\n",
    "        \n",
    "        results = forecaster.forecast(\n",
    "            X_train_from_test_pct, y_train_from_test_pct,\n",
    "            X_test_pct, y_test_pct, test_country,\n",
    "            y_train_from_test_original, y_test_original\n",
    "        )\n",
    "        \n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69a4539",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleCountryModel:\n",
    "    def __init__(self, features, target):\n",
    "        self.features = features\n",
    "        self.target = target\n",
    "\n",
    "    def run_single_country(self, data, country, model_func=build_lstm):\n",
    "        print(f\"\\nSingle Country Model for {country}\")\n",
    "        print(f\"Predicting ({self.target}) and all targets and their lags are used as features\")\n",
    "\n",
    "        # Applying pct change normalisation\n",
    "        data = pct_change_features(data)\n",
    "\n",
    "        country_data = data[data['country'] == country].sort_values('year')\n",
    "\n",
    "        # Use all targets (pct)\n",
    "        country_data, feature_cols, target_col = prepare_features_with_target_lags(\n",
    "            country_data, self.features, self.target, use_lags=True\n",
    "        )\n",
    "\n",
    "        original_target_col = f'{self.target}_original'\n",
    "\n",
    "        valid_cols = feature_cols + [target_col]\n",
    "        if original_target_col in country_data.columns:\n",
    "            valid_cols.append(original_target_col)\n",
    "\n",
    "        valid_data = country_data[valid_cols].dropna()\n",
    "\n",
    "        if len(valid_cols) == 0:\n",
    "            print(f\"No valid data for {country}\")\n",
    "            return None\n",
    "        \n",
    "        n_samples = len(valid_data)\n",
    "        n_test = TEST_SAMPLES\n",
    "        n_train = n_samples - n_test\n",
    "\n",
    "        if n_train < N_STEPS_IN + N_STEPS_OUT:\n",
    "            print(f\"Not enough training data for {country}\")\n",
    "            return None\n",
    "        \n",
    "        X_pct = valid_data[feature_cols].values\n",
    "        y_pct = valid_data[target_col].values\n",
    "        y_original = valid_data[original_target_col].values if original_target_col in valid_data.columns else None\n",
    "        \n",
    "        X_train_pct = X_pct[:n_train]\n",
    "        y_train_pct = y_pct[:n_train]\n",
    "        y_train_original = y_original[:n_train] if y_original is not None else None\n",
    "        \n",
    "        X_test_pct = X_pct[n_train:n_train + n_test]\n",
    "        y_test_pct = y_pct[n_train:n_train + n_test]\n",
    "        y_test_original = y_original[n_train:n_train + n_test] if y_original is not None else None\n",
    "        \n",
    "        print(f\"Training samples: {len(X_train_pct)}\")\n",
    "        print(f\"Test samples: {len(X_test_pct)}\")\n",
    "        print(f\"Number of features: {X_train_pct.shape[1]}\")\n",
    "\n",
    "        forecaster = LOCOForecaster(model_func)\n",
    "        \n",
    "        X_dict = {country: X_train_pct}\n",
    "        y_dict = {country: y_train_pct}\n",
    "        \n",
    "        forecaster.train_model(X_dict, y_dict, [country])\n",
    "        \n",
    "        results = forecaster.forecast(\n",
    "            X_train_pct, y_train_pct,\n",
    "            X_test_pct, y_test_pct, country,\n",
    "            y_train_original, y_test_original\n",
    "        )\n",
    "        \n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60d688d",
   "metadata": {},
   "source": [
    "### Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6faea67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_comparison(results, country, target, save_dir='data_export/04_plots'):\n",
    "    os.makedirs(os.path.join(save_dir, 'breakdown_plots'), exist_ok=True)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 4, figsize=(20, 5))\n",
    "    fig.suptitle(f'{country} - {target}: Breakdown LOCO vs Single Country', fontsize=16)\n",
    "    \n",
    "    model_types = ['loco', 'single']\n",
    "    model_labels = ['All Targets LOCO', 'Single Country']\n",
    "\n",
    "    for model_idx, (model_type, model_label) in enumerate(zip(model_types, model_labels)):\n",
    "        if model_type not in results:\n",
    "            continue\n",
    "\n",
    "        model_results = results[model_type]\n",
    "\n",
    "        # Actual values comparison\n",
    "        if model_results['predictions_actual'] is not None:\n",
    "            predictions_actual = np.array(model_results['predictions_actual']).flatten()\n",
    "            actuals_actual = np.array(model_results['actuals_actual']).flatten()\n",
    "            \n",
    "            # Ensure both arrays have the same length\n",
    "            min_len = min(len(predictions_actual), len(actuals_actual))\n",
    "            predictions_actual = predictions_actual[:min_len]\n",
    "            actuals_actual = actuals_actual[:min_len]\n",
    "            \n",
    "            ax1 = axes[0, model_idx * 2]\n",
    "            ax1.plot(actuals_actual, label='Actual', alpha=0.8, linewidth=2, color='blue')\n",
    "            ax1.plot(predictions_actual, label='Predicted', alpha=0.8, linewidth=2, color='orange')\n",
    "            ax1.set_title(f'{model_label} - Actual Values')\n",
    "            ax1.set_xlabel('Time Step')\n",
    "            ax1.set_ylabel(f'{target} (Actual)')\n",
    "            ax1.legend(loc='upper left')\n",
    "\n",
    "            # Iteration markers\n",
    "            for i in [2.5, 5.5]:\n",
    "                if i < len(predictions_actual):\n",
    "                    ax1.axvline(x=i, color='gray', linestyle=':', alpha=0.3)\n",
    "\n",
    "            # Residuals for actual values\n",
    "            residuals_actual = predictions_actual - actuals_actual\n",
    "            ax2 = axes[0, model_idx * 2 + 1]\n",
    "            colors = ['red' if r > 0 else 'blue' for r in residuals_actual]\n",
    "            ax2.bar(range(len(residuals_actual)), residuals_actual, alpha=0.7, color=colors)\n",
    "            ax2.axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "            ax2.set_title(f'Residuals - Actual Values')\n",
    "            ax2.set_xlabel('Time Step')\n",
    "            ax2.set_ylabel('Error (Actual)')\n",
    "\n",
    "            # Metrics (actual values)\n",
    "            overall_rmse = rmse(predictions_actual, actuals_actual)\n",
    "            metrics_text = f'RMSE: {overall_rmse:.4f}'\n",
    "            ax1.text(0.02, 0.98, metrics_text, transform=ax1.transAxes, va='top', ha='left',\n",
    "                    bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.7), fontsize=9)\n",
    "        \n",
    "        # pct change comparison - Fixed the shape mismatch issue\n",
    "        predictions_pct = np.array(model_results['predictions_pct']).flatten()\n",
    "        actuals_pct = np.array(model_results['actuals_pct']).flatten()\n",
    "        \n",
    "        # Ensure both arrays have the same length\n",
    "        min_len_pct = min(len(predictions_pct), len(actuals_pct))\n",
    "        predictions_pct = predictions_pct[:min_len_pct]\n",
    "        actuals_pct = actuals_pct[:min_len_pct]\n",
    "        \n",
    "        ax3 = axes[1, model_idx * 2]\n",
    "        ax3.plot(actuals_pct, label='Actual', alpha=0.8, linewidth=2, color='blue')\n",
    "        ax3.plot(predictions_pct, label='Predicted', alpha=0.8, linewidth=2, color='orange')\n",
    "        ax3.set_title(f'{model_label} - Percentage Change')\n",
    "        ax3.set_xlabel('Time Step')\n",
    "        ax3.set_ylabel(f'{target} (% Change)')\n",
    "        ax3.legend(loc='upper left')\n",
    "\n",
    "        # Iteration markers\n",
    "        for i in [2.5, 5.5]:\n",
    "            if i < len(predictions_pct):\n",
    "                ax3.axvline(x=i, color='gray', linestyle=':', alpha=0.3)\n",
    "\n",
    "        # Residuals for pct change\n",
    "        residuals_pct = predictions_pct - actuals_pct\n",
    "        ax4 = axes[1, model_idx * 2 + 1]\n",
    "        colors = ['red' if r > 0 else 'blue' for r in residuals_pct]\n",
    "        ax4.bar(range(len(residuals_pct)), residuals_pct, alpha=0.7, color=colors)\n",
    "        ax4.axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "        ax4.set_title(f'Residuals - % Change')\n",
    "        ax4.set_xlabel('Time Step')\n",
    "        ax4.set_ylabel('Error (% Change)')\n",
    "\n",
    "        # Metrics (pct change)\n",
    "        overall_rmse_pct = rmse(predictions_pct, actuals_pct)\n",
    "        metrics_text_pct = f'RMSE: {overall_rmse_pct:.4f}'\n",
    "        ax3.text(0.02, 0.98, metrics_text_pct, transform=ax3.transAxes, va='top', ha='left',\n",
    "                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.7), fontsize=9)\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plot_path = os.path.join(save_dir, 'breakdown_plots', f'{country}_{target}_breakdown_comparison.png')\n",
    "    plt.savefig(plot_path, dpi=150, bbox_inches='tight')\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4b4925",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_performance_summary(all_results_dict, save_dir='data_export/04_results/breakdown'):\n",
    "    performance_records = []\n",
    "\n",
    "    for experiment_name, experiment_data in all_results_dict.items():\n",
    "        for model_type in ['loco', 'single']:\n",
    "            country_rmses = {}\n",
    "\n",
    "            for country, country_results in experiment_data.items():\n",
    "                if model_type in country_results:\n",
    "                    results = country_results[model_type]\n",
    "\n",
    "                    # RNSE on actual values if possible\n",
    "                    if results['predictions_actual'] is not None:\n",
    "                        preds = results['predictions_actual']\n",
    "                        acts = results['actuals_actual']\n",
    "                    else:\n",
    "                        preds = results['predictions_pct']\n",
    "                        acts = results['actuals_pct']\n",
    "                    \n",
    "                    if len(preds) > 0:\n",
    "                        country_rmse = rmse(preds, acts)\n",
    "                        country_rmses[country] = country_rmse\n",
    "\n",
    "            if country_rmses:\n",
    "                avg_rmse = np.mean(list(country_rmses.values()))\n",
    "                min_rmse = np.min(list(country_rmses.values()))\n",
    "                max_rmse = np.max(list(country_rmses.values()))\n",
    "                \n",
    "                # Find countries with min and max RMSE\n",
    "                min_country = min(country_rmses, key=country_rmses.get)\n",
    "                max_country = max(country_rmses, key=country_rmses.get)\n",
    "                \n",
    "                performance_records.append({\n",
    "                    'name': experiment_name,\n",
    "                    'strategy': model_type,\n",
    "                    'avg_rmse': avg_rmse,\n",
    "                    'min_rmse': min_rmse,\n",
    "                    'max_rmse': max_rmse,\n",
    "                    'min_rmse_country': min_country,\n",
    "                    'max_rmse_country': max_country\n",
    "                })\n",
    "\n",
    "    performance_df = pd.DataFrame(performance_records)\n",
    "\n",
    "    summary_path = os.path.join(save_dir, 'model_performance_summary.csv')\n",
    "\n",
    "    if os.path.exists(summary_path):\n",
    "        existing_df = pd.read_csv(summary_path)\n",
    "        performance_df = pd.concat([existing_df, performance_df], ignore_index=True)\n",
    "\n",
    "    performance_df.to_csv(summary_path, index=False)\n",
    "\n",
    "    return performance_df    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c472b893",
   "metadata": {},
   "source": [
    "### Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20b3dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_comparison(countries_to_test, target='co2', model_func=build_lstm, \n",
    "                           save_dir='data_export/04_results/breakdown', country_group='all', experiment_name=None):\n",
    "    \n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    if experiment_name is None:\n",
    "        experiment_name = f\"{target}_{model_func.__name__}_{country_group}\"\n",
    "\n",
    "    print(\"\\nENHANCED LOCO vs SINGLE COUNTRY COMPARISON\")\n",
    "    print(f\"Experiment: {experiment_name}\")\n",
    "    print(f\"Target: {target}\")\n",
    "    print(f\"Model: {model_func.__name__}\")\n",
    "    print(f\"Test size: {TEST_SAMPLES} samples\")\n",
    "    print(f\"Country group: {country_group}\")\n",
    "\n",
    "    data = load_data()\n",
    "\n",
    "    if country_group == 'developed':\n",
    "        training_data = DEVELOPED_COUNTRIES\n",
    "    elif country_group == 'developing':\n",
    "        training_data = DEVELOPING_COUNTRIES\n",
    "    else:\n",
    "        training_data = G20_COUNTRIES\n",
    "\n",
    "    loco_comparison = LOCOComparison(training_data, FEATURES, target)\n",
    "    single_country_model = SingleCountryModel(FEATURES, target)\n",
    "\n",
    "    all_results = {}\n",
    "\n",
    "    for test_country in countries_to_test:\n",
    "        print(f\"\\nTESTING COUNTRY: {test_country}\")\n",
    "\n",
    "        country_results = {}\n",
    "        \n",
    "        print(f\"\\nLOCO MODEL\")\n",
    "        loco_results = loco_comparison.run_comparison(data, test_country, model_func)\n",
    "        if loco_results is not None:\n",
    "            country_results['loco'] = loco_results\n",
    "\n",
    "        print(\"\\nSINGLE COUNTRY MODEL\")\n",
    "        single_results = single_country_model.run_single_country(data, test_country, model_func)\n",
    "        if single_results is not None:\n",
    "            country_results['single'] = single_results\n",
    "        \n",
    "        all_results[test_country] = country_results\n",
    "\n",
    "        if country_results:\n",
    "            fig = plot_comparison(\n",
    "                country_results, \n",
    "                test_country, \n",
    "                target,\n",
    "                save_dir=save_dir\n",
    "            )\n",
    "            plt.show()\n",
    "\n",
    "    experiment_results = {experiment_name: all_results}\n",
    "    performance_summary = create_performance_summary(experiment_results, save_dir)\n",
    "\n",
    "    print(f\"\\nPERFORMANCE SUMMARY\")\n",
    "    current_exp_summary = performance_summary[performance_summary['name'] == experiment_name]\n",
    "\n",
    "    # Save the metrics\n",
    "    stepwise_path = os.path.join(save_dir, f'{experiment_name}_stepwise_metrics.pkl')\n",
    "    with open(stepwise_path, 'wb') as f:\n",
    "        pickle.dump(all_results, f)\n",
    "    \n",
    "    clear_memory()\n",
    "    \n",
    "    return all_results, performance_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527c222e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table(all_results_dict, save_dir='data_export/04_results/breakdown'):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    detailed_records = []\n",
    "    \n",
    "    for experiment_name, experiment_data in all_results_dict.items():\n",
    "        for country, country_results in experiment_data.items():\n",
    "            for model_type in ['loco', 'single']:\n",
    "                if model_type in country_results:\n",
    "                    stepwise_df = country_results[model_type]['stepwise_metrics']\n",
    "\n",
    "                    # Pivot record\n",
    "                    record = {\n",
    "                        'Country': country,\n",
    "                        'Model': model_type,\n",
    "                        'Experiment': experiment_name\n",
    "                    }\n",
    "\n",
    "                    # RMSE for each iteration and step\n",
    "                    for _, row in stepwise_df.iterrows():\n",
    "                        iter_step_key = f\"Iter{row['iteration']}_Step{row['step']}\"\n",
    "                        record[f\"{iter_step_key}_RMSE_pct\"] = row['rmse_pct']\n",
    "                        record[f\"{iter_step_key}_RMSE_actual\"] = row['rmse_actual']\n",
    "                    \n",
    "                    detailed_records.append(record)\n",
    "    \n",
    "    detailed_df = pd.DataFrame(detailed_records)\n",
    "    \n",
    "    # Save detailed table\n",
    "    detailed_path = os.path.join(save_dir, 'detailed_iteration_rmse.csv')\n",
    "    detailed_df.to_csv(detailed_path, index=False)\n",
    "    \n",
    "    return detailed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c93b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_summary_stats_table(all_results_dict, save_dir='data_export/04_results/breakdown'):\n",
    "    summary_records = []\n",
    "    \n",
    "    for experiment_name, experiment_data in all_results_dict.items():\n",
    "        for country, country_results in experiment_data.items():\n",
    "            for model_type in ['loco', 'single']:\n",
    "                if model_type in country_results:\n",
    "                    stepwise_df = country_results[model_type]['stepwise_metrics']\n",
    "                    \n",
    "                    # Calculate summary statistics\n",
    "                    summary_record = {\n",
    "                        'Country': country,\n",
    "                        'Model': model_type,\n",
    "                        'Experiment': experiment_name,\n",
    "                        'Avg_RMSE_pct': stepwise_df['rmse_pct'].mean(),\n",
    "                        'Min_RMSE_pct': stepwise_df['rmse_pct'].min(),\n",
    "                        'Max_RMSE_pct': stepwise_df['rmse_pct'].max(),\n",
    "                        'Std_RMSE_pct': stepwise_df['rmse_pct'].std(),\n",
    "                        'Avg_RMSE_actual': stepwise_df['rmse_actual'].mean(),\n",
    "                        'Min_RMSE_actual': stepwise_df['rmse_actual'].min(),\n",
    "                        'Max_RMSE_actual': stepwise_df['rmse_actual'].max(),\n",
    "                        'Std_RMSE_actual': stepwise_df['rmse_actual'].std(),\n",
    "                        'Total_Steps': len(stepwise_df),\n",
    "                        'Best_Iteration_pct': stepwise_df.groupby('iteration')['rmse_pct'].mean().idxmin(),\n",
    "                        'Worst_Iteration_pct': stepwise_df.groupby('iteration')['rmse_pct'].mean().idxmax()\n",
    "                    }\n",
    "                    \n",
    "                    summary_records.append(summary_record)\n",
    "    \n",
    "    summary_df = pd.DataFrame(summary_records)\n",
    "\n",
    "    summary_path = os.path.join(save_dir, 'summary_statistics_rmse.csv')\n",
    "    summary_df.to_csv(summary_path, index=False)\n",
    "    \n",
    "    return summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7ef657",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_readme(deatiled_df, summary_df, save_dir='data_export/04_results/breakdown'):\n",
    "\n",
    "    readme_content = \"\"\"# LOCO vs Single Country Model Comparison - Results Analysis\n",
    "\n",
    "## Model Configuration\n",
    "- **Input Steps**: 5 time steps\n",
    "- **Output Steps**: 3 time steps  \n",
    "- **Test Samples**: 9 per country\n",
    "- **Target Variable**: CO2 emissions\n",
    "- **Countries**: Developed countries (G20)\n",
    "\n",
    "## Overall Performance\n",
    "\"\"\"\n",
    "\n",
    "    if not summary_df.empty:\n",
    "        readme_content += \"\\n### Summary Statistics (RMSE)\\n\\n\"\n",
    "\n",
    "        summary_table = summary_df.groupby('Model').agg({\n",
    "            'Avg_RMSE_pct': ['mean', 'std'],\n",
    "            'Avg_RMSE_actual': ['mean', 'std']\n",
    "        }).round(4)\n",
    "\n",
    "        readme_content += summary_table.to_string() + \"\\n\\n\"\n",
    "\n",
    "        best_loco = summary_df[summary_df['Model'] == 'loco'].loc[summary_df[summary_df['Model'] == 'loco']['Avg_RMSE_pct'].idxmin()]\n",
    "        worst_loco = summary_df[summary_df['Model'] == 'loco'].loc[summary_df[summary_df['Model'] == 'loco']['Avg_RMSE_pct'].idxmax()]\n",
    "        \n",
    "        readme_content += f\"\"\"\n",
    "### Performance\n",
    "**LOCO Model:**\n",
    "- Best performing country: {best_loco['Country']} (Avg RMSE pct: {best_loco['Avg_RMSE_pct']:.4f})\n",
    "- Worst performing country: {worst_loco['Country']} (Avg RMSE pct: {worst_loco['Avg_RMSE_pct']:.4f})\n",
    "\n",
    "\"\"\"\n",
    "    readme_path = os.path.join(save_dir, 'README.md')\n",
    "    with open(readme_path, 'w') as f:\n",
    "        f.write(readme_content)\n",
    "    \n",
    "    print(f\"README file saved to: {readme_path}\")\n",
    "    return readme_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3e8ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all():\n",
    "    models = {\n",
    "        'lstm': build_lstm,\n",
    "        'bilstm': build_bilstm, \n",
    "        'edlstm': build_edlstm,\n",
    "        'cnn': build_cnn\n",
    "    }\n",
    "    \n",
    "    targets = ['co2', 'gdp', 'primary_energy_consumption']\n",
    "    \n",
    "    country_groups = {\n",
    "        'developed': DEVELOPED_COUNTRIES,\n",
    "        'developing': DEVELOPING_COUNTRIES\n",
    "    }\n",
    "\n",
    "    all_experiments_results = {}\n",
    "\n",
    "    experiment_count = 0\n",
    "    total_experiments = len(models) * len(targets) * len(country_groups)\n",
    "    \n",
    "    for model_name, model_func in models.items():\n",
    "        for target in targets:\n",
    "            for group_name, countries in country_groups.items():\n",
    "                \n",
    "                experiment_count += 1\n",
    "                experiment_name = f\"{target}_{model_name}_{group_name}\"\n",
    "                \n",
    "                print(f\"Experiment {experiment_count}/{total_experiments}: {experiment_name}\")\n",
    "                \n",
    "                try:\n",
    "                    # Run the experiment\n",
    "                    results, summary = run_comparison(\n",
    "                        countries_to_test=countries,\n",
    "                        target=target,\n",
    "                        model_func=model_func,\n",
    "                        save_dir=f'data_export/04_results/breakdown/{group_name}',\n",
    "                        country_group=group_name,\n",
    "                        experiment_name=experiment_name\n",
    "                    )\n",
    "                    \n",
    "                    # Store results\n",
    "                    all_experiments_results[experiment_name] = results\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Failed: {experiment_name} - Error: {str(e)}\")\n",
    "                    continue\n",
    "    \n",
    "    return all_experiments_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cb45ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"def generate_all_comp(all_results):\n",
    "    save_dir = 'data_export/04_results/breakdown/overall'\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    detailed_df = create_table(all_results, save_dir)\n",
    "    summary_df = create_summary_stats_table(all_results, save_dir)\n",
    "    \n",
    "    # Create model comparison table\n",
    "    model_comparison = create_table(summary_df, save_dir)\n",
    "    \n",
    "    # Create target comparison table  \n",
    "    target_comparison = create_summary_stats_table(summary_df, save_dir)\n",
    "    \n",
    "    # Generate comprehensive README\n",
    "    generate_comp_readme(detailed_df, summary_df, model_comparison, target_comparison, save_dir)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94d78dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"def all_analysis(all_results):\n",
    "    for group_name in ['developed', 'developing']:\n",
    "        group_results = {k: v for k, v in all_results.items() if group_name in k}\n",
    "        \n",
    "        if not group_results:\n",
    "            continue\n",
    "            \n",
    "        save_dir = f'data_export/04_results/breakdown/{group_name}'\n",
    "        \n",
    "        print(f\"\\nAnalyzing {group_name} countries...\")\n",
    "        \n",
    "        # Generate tables\n",
    "        detailed_df = create_table(group_results, save_dir)\n",
    "        summary_df = create_summary_stats_table(group_results, save_dir)\n",
    "        \n",
    "        # Generate group-specific README\n",
    "        make_readme(detailed_df, summary_df, save_dir)\n",
    "    \n",
    "    generate\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59073551",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_developed_lstm_co2(target='co2', model_func=build_lstm):\n",
    "    return run_comparison(\n",
    "        countries_to_test=DEVELOPED_COUNTRIES,\n",
    "        target=target,\n",
    "        model_func=model_func,\n",
    "        save_dir='data_export/04_results/breakdown/developed',\n",
    "        country_group='developed'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cc0c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_co2_results, lstm_co2_summary = run_developed_lstm_co2()\n",
    "co2_lstm_combined_results = {'co2_build_lstm_developed': lstm_co2_results}\n",
    "co2_lstm_detailed_table = create_table(co2_lstm_combined_results)\n",
    "co2_lstm_summary_table = create_summary_stats_table(co2_lstm_combined_results)\n",
    "co2_lstm_readme_content = make_readme(co2_lstm_detailed_table, co2_lstm_summary_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89331b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_developed_bilstm_co2(target='co2', model_func=build_bilstm):\n",
    "    return run_comparison(\n",
    "        countries_to_test=DEVELOPED_COUNTRIES,\n",
    "        target=target,\n",
    "        model_func=model_func,\n",
    "        save_dir='data_export/04_results/breakdown/developed',\n",
    "        country_group='developed'\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
